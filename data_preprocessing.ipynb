{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\MADS\\696\\696\\env696\\Scripts\\python.exe\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\python.exe\n",
      "C:\\Users\\user\\AppData\\Local\\Microsoft\\WindowsApps\\python.exe\n"
     ]
    }
   ],
   "source": [
    "!where python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this code to make sure you install all the required libraries\n",
    "# be sure you are in virtual environment before install, otherwise it will overwrite your local environment\n",
    "\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "RANDOM_SEED = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anime = pd.read_csv(\"assets/anime.csv\")\n",
    "df_manga = pd.read_csv(\"assets/manga.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24985, 39), (64833, 30))"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anime.shape, df_manga.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prepocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some short synopsis contain no information about the story of manga/title. This will introduce noise to our model. Therefore, we decide to remove those rows with extremely short synopsis.\n",
    "Example:\n",
    "- Second season of Mao Zhi Ming.\n",
    "- The second season of Shen Lan Qi Yu Wushuang Zhu.\n",
    "- Recap episode of Hakyuu Houshin Engi.\n",
    "- Fifth Season of Bungou Stray Dogs\n",
    "- 1-3. Ba_ku\\n4-5. Mephisto\n",
    "- An absurd film by Kuri Youji.\n",
    "- Included one-shot:\\nBougainvillea\n",
    "- A collection of oneshots by Nishida Higashi.\n",
    "- A movie adaptation of the TV series.\n",
    "- Short film by Kurosaka Keita.\n",
    "- Special episodes added to DVDs and Blu-rays.\n",
    "- Movie based on the 1996 TV anime with an original plot.\n",
    "- Third season of Yuan Long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned anime shape:  (8863, 23)\n",
      "cleaned manga shape:  (15454, 23)\n"
     ]
    }
   ],
   "source": [
    "def data_cleaning(input_anime, input_manga):\n",
    "    df_anime = input_anime.copy()\n",
    "    df_manga = input_manga.copy()\n",
    "\n",
    "    # remove unnecessary columns\n",
    "    df_anime = df_anime.drop(columns=['anime_id', 'total_duration', 'start_year', 'start_season', 'rating', 'main_picture', 'url', 'trailer_url', 'background', 'created_at', 'updated_at', 'episode_duration', 'broadcast_day', 'broadcast_time', 'licensors', 'title_synonyms'])\n",
    "    df_manga = df_manga.drop(columns=['manga_id', 'main_picture', 'url', 'background', 'created_at_before', 'updated_at', 'title_synonyms'])\n",
    "\n",
    "    # remove rows that are null in 'synopsis' and 'title', which are crucial for our project\n",
    "    df_anime.dropna(subset=['title', 'synopsis', 'title_english', 'title_japanese'], inplace=True)\n",
    "    df_manga.dropna(subset=['title', 'synopsis', 'title_english', 'title_japanese'], inplace=True)\n",
    "\n",
    "    # remove '(Sources:...)' from synopsis\n",
    "    df_anime['synopsis'] = df_anime['synopsis'].apply(lambda x: re.sub(r'\\(Source:.*\\)', '', x))\n",
    "    df_manga['synopsis'] = df_manga['synopsis'].apply(lambda x: re.sub(r'\\(Source:.*\\)', '', x))\n",
    "\n",
    "    # remove '[Written by ...]' from synopsis\n",
    "    df_anime['synopsis'] = df_anime['synopsis'].apply(lambda x: re.sub(r'\\[Written by.*\\]', '', x))\n",
    "    df_manga['synopsis'] = df_manga['synopsis'].apply(lambda x: re.sub(r'\\[Written by.*\\]', '', x))\n",
    "\n",
    "    # remove rows that have extreme short synopsis\n",
    "    df_anime = df_anime[df_anime['synopsis'].apply(lambda x: len(x) > 50)]\n",
    "    df_manga = df_manga[df_manga['synopsis'].apply(lambda x: len(x) > 50)]\n",
    "\n",
    "    print('cleaned anime shape: ', df_anime.shape)\n",
    "    print('cleaned manga shape: ', df_manga.shape)\n",
    "\n",
    "    return df_anime, df_manga\n",
    "\n",
    "df_anime_cleaned, df_manga_cleaned = data_cleaning(df_anime, df_manga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anime extra columns: \n",
      " ['episodes', 'source', 'studios', 'producers']\n"
     ]
    }
   ],
   "source": [
    "print(\"anime extra columns: \\n\", [col for col in df_anime_cleaned.columns if not col in df_manga_cleaned.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manga extra columns: \n",
      " ['volumes', 'chapters', 'authors', 'serializations']\n"
     ]
    }
   ],
   "source": [
    "print(\"manga extra columns: \\n\", [col for col in df_manga_cleaned.columns if not col in df_anime_cleaned.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common columns: \n",
      " ['title', 'type', 'score', 'scored_by', 'status', 'start_date', 'end_date', 'members', 'favorites', 'sfw', 'approved', 'real_start_date', 'real_end_date', 'genres', 'themes', 'demographics', 'synopsis', 'title_english', 'title_japanese']\n"
     ]
    }
   ],
   "source": [
    "print(\"common columns: \\n\", [col for col in df_anime_cleaned.columns if col in df_manga_cleaned.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['manga', 'manhwa', 'light_novel', 'one_shot', 'manhua', 'novel',\n",
       "       'doujinshi'], dtype=object)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_manga['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['manga', 'visual_novel', 'original', 'web_manga', 'light_novel',\n",
       "       'novel', 'game', '4_koma_manga', 'music', 'other', 'web_novel',\n",
       "       'card_game', 'book', 'mixed_media', nan, 'picture_book', 'radio'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anime['source'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tv', 'movie', 'ona', 'ova', 'special', 'music', nan], dtype=object)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anime['type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra columns alignment**:\n",
    "| anime columns | manga columns | combine |\n",
    "| --- | --- | --- |\n",
    "| episodes | chapters | episodes/chapters |\n",
    "| NULL | volumes |\n",
    "| source | type | original_source |\n",
    "| type | NULL |\n",
    "| total_duration | NULL |\n",
    "| rating | NULL |\n",
    "| start_year | NULL |\n",
    "| start_season | NULL |\n",
    "| studios | NULL |\n",
    "| producers | NULL |\n",
    "| NULL | authors |\n",
    "| NULL | serializations |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def extract_author_name(author_list):\n",
    "    try:\n",
    "        author_list = ast.literal_eval(author_list)\n",
    "        \n",
    "        # Extract first and last names of authors, ignoring the others\n",
    "        author_names = [f\"{author['first_name']} {author['last_name']}\".strip() for author in author_list if author['first_name'] or author['last_name']]\n",
    "        \n",
    "        # Join names for multiple authors\n",
    "        return ', '.join(author_names) if author_names else \"Missing\"\n",
    "    \n",
    "    except (ValueError, SyntaxError, KeyError, TypeError):\n",
    "        # Handle Missing data\n",
    "        return \"Missing\"\n",
    "\n",
    "# Apply the function to the 'authors' column\n",
    "def authors_extraction(input_manga):\n",
    "    df_manga = input_manga.copy()\n",
    "    df_manga['authors'] = df_manga['authors'].apply(extract_author_name)\n",
    "\n",
    "    return df_manga\n",
    "\n",
    "df_manga_extracted = authors_extraction(df_manga_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_alignment(input_anime, input_manga):\n",
    "    df_anime = input_anime.copy()\n",
    "    df_manga = input_manga.copy()\n",
    "\n",
    "    # treat 'episodes' and 'chapters' the same, create null value for 'volume' in anime\n",
    "    df_anime.rename(columns={'episodes': 'episodes/chapters'}, inplace=True)\n",
    "    df_manga.rename(columns={'chapters': 'episodes/chapters'}, inplace=True)\n",
    "\n",
    "    # Combine studios and authors together to get creators columns\n",
    "    df_anime.rename(columns={'studios': 'creators'}, inplace=True)\n",
    "    df_manga.rename(columns={'authors': 'creators'}, inplace=True)\n",
    "\n",
    "    # Also for producers and serialization\n",
    "    df_anime.rename(columns={'producers': 'production_source'}, inplace=True)\n",
    "    df_manga.rename(columns={'serializations': 'production_source'}, inplace=True)\n",
    "\n",
    "    # To distinguish where the data from\n",
    "    df_anime['is_anime'] = 1\n",
    "    df_manga['is_anime'] = 0 \n",
    "    \n",
    "    return df_anime, df_manga\n",
    "\n",
    "df_anime_aligned, df_manga_aligned = columns_alignment(df_anime_cleaned, df_manga_extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>score</th>\n",
       "      <th>scored_by</th>\n",
       "      <th>status</th>\n",
       "      <th>episodes/chapters</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>source</th>\n",
       "      <th>members</th>\n",
       "      <th>favorites</th>\n",
       "      <th>sfw</th>\n",
       "      <th>approved</th>\n",
       "      <th>genres</th>\n",
       "      <th>themes</th>\n",
       "      <th>demographics</th>\n",
       "      <th>creators</th>\n",
       "      <th>production_source</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>title_english</th>\n",
       "      <th>title_japanese</th>\n",
       "      <th>is_anime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>tv</td>\n",
       "      <td>9.10</td>\n",
       "      <td>2037075</td>\n",
       "      <td>finished_airing</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2009-04-05</td>\n",
       "      <td>2010-07-04</td>\n",
       "      <td>manga</td>\n",
       "      <td>3206028</td>\n",
       "      <td>219036</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>['Action', 'Adventure', 'Drama', 'Fantasy']</td>\n",
       "      <td>['Military']</td>\n",
       "      <td>['Shounen']</td>\n",
       "      <td>['Bones']</td>\n",
       "      <td>['Aniplex', 'Square Enix', 'Mainichi Broadcast...</td>\n",
       "      <td>After a horrific alchemy experiment goes wrong...</td>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>鋼の錬金術師 FULLMETAL ALCHEMIST</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hunter x Hunter (2011)</td>\n",
       "      <td>tv</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1671587</td>\n",
       "      <td>finished_airing</td>\n",
       "      <td>148.0</td>\n",
       "      <td>2011-10-02</td>\n",
       "      <td>2014-09-24</td>\n",
       "      <td>manga</td>\n",
       "      <td>2688079</td>\n",
       "      <td>202109</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>['Action', 'Adventure', 'Fantasy']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Shounen']</td>\n",
       "      <td>['Madhouse']</td>\n",
       "      <td>['VAP', 'Nippon Television Network', 'Shueisha']</td>\n",
       "      <td>Hunters devote themselves to accomplishing haz...</td>\n",
       "      <td>Hunter x Hunter</td>\n",
       "      <td>HUNTER×HUNTER（ハンター×ハンター）</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shingeki no Kyojin Season 3 Part 2</td>\n",
       "      <td>tv</td>\n",
       "      <td>9.05</td>\n",
       "      <td>1491491</td>\n",
       "      <td>finished_airing</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2019-04-29</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>manga</td>\n",
       "      <td>2133927</td>\n",
       "      <td>55644</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>['Action', 'Drama']</td>\n",
       "      <td>['Gore', 'Military', 'Survival']</td>\n",
       "      <td>['Shounen']</td>\n",
       "      <td>['Wit Studio']</td>\n",
       "      <td>['Production I.G', 'Dentsu', 'Mainichi Broadca...</td>\n",
       "      <td>Seeking to restore humanity's diminishing hope...</td>\n",
       "      <td>Attack on Titan Season 3 Part 2</td>\n",
       "      <td>進撃の巨人 Season3 Part.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Steins;Gate</td>\n",
       "      <td>tv</td>\n",
       "      <td>9.07</td>\n",
       "      <td>1348232</td>\n",
       "      <td>finished_airing</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2011-04-06</td>\n",
       "      <td>2011-09-14</td>\n",
       "      <td>visual_novel</td>\n",
       "      <td>2463954</td>\n",
       "      <td>184312</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>['Drama', 'Sci-Fi', 'Suspense']</td>\n",
       "      <td>['Psychological', 'Time Travel']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['White Fox']</td>\n",
       "      <td>['Frontier Works', 'Media Factory', 'Kadokawa ...</td>\n",
       "      <td>Eccentric scientist Rintarou Okabe has a never...</td>\n",
       "      <td>Steins;Gate</td>\n",
       "      <td>STEINS;GATE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Koe no Katachi</td>\n",
       "      <td>movie</td>\n",
       "      <td>8.94</td>\n",
       "      <td>1540277</td>\n",
       "      <td>finished_airing</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-09-17</td>\n",
       "      <td>2016-09-17</td>\n",
       "      <td>manga</td>\n",
       "      <td>2218467</td>\n",
       "      <td>84124</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>['Award Winning', 'Drama']</td>\n",
       "      <td>['Romantic Subtext']</td>\n",
       "      <td>['Shounen']</td>\n",
       "      <td>['Kyoto Animation']</td>\n",
       "      <td>['Shochiku', 'Pony Canyon', 'Kodansha', 'ABC A...</td>\n",
       "      <td>As a wild youth, elementary school student Sho...</td>\n",
       "      <td>A Silent Voice</td>\n",
       "      <td>聲の形</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title   type  score  scored_by  \\\n",
       "0    Fullmetal Alchemist: Brotherhood     tv   9.10    2037075   \n",
       "1              Hunter x Hunter (2011)     tv   9.04    1671587   \n",
       "2  Shingeki no Kyojin Season 3 Part 2     tv   9.05    1491491   \n",
       "3                         Steins;Gate     tv   9.07    1348232   \n",
       "4                      Koe no Katachi  movie   8.94    1540277   \n",
       "\n",
       "            status  episodes/chapters  start_date    end_date        source  \\\n",
       "0  finished_airing               64.0  2009-04-05  2010-07-04         manga   \n",
       "1  finished_airing              148.0  2011-10-02  2014-09-24         manga   \n",
       "2  finished_airing               10.0  2019-04-29  2019-07-01         manga   \n",
       "3  finished_airing               24.0  2011-04-06  2011-09-14  visual_novel   \n",
       "4  finished_airing                1.0  2016-09-17  2016-09-17         manga   \n",
       "\n",
       "   members  favorites   sfw  approved  \\\n",
       "0  3206028     219036  True      True   \n",
       "1  2688079     202109  True      True   \n",
       "2  2133927      55644  True      True   \n",
       "3  2463954     184312  True      True   \n",
       "4  2218467      84124  True      True   \n",
       "\n",
       "                                        genres  \\\n",
       "0  ['Action', 'Adventure', 'Drama', 'Fantasy']   \n",
       "1           ['Action', 'Adventure', 'Fantasy']   \n",
       "2                          ['Action', 'Drama']   \n",
       "3              ['Drama', 'Sci-Fi', 'Suspense']   \n",
       "4                   ['Award Winning', 'Drama']   \n",
       "\n",
       "                             themes demographics             creators  \\\n",
       "0                      ['Military']  ['Shounen']            ['Bones']   \n",
       "1                                []  ['Shounen']         ['Madhouse']   \n",
       "2  ['Gore', 'Military', 'Survival']  ['Shounen']       ['Wit Studio']   \n",
       "3  ['Psychological', 'Time Travel']           []        ['White Fox']   \n",
       "4              ['Romantic Subtext']  ['Shounen']  ['Kyoto Animation']   \n",
       "\n",
       "                                   production_source  \\\n",
       "0  ['Aniplex', 'Square Enix', 'Mainichi Broadcast...   \n",
       "1   ['VAP', 'Nippon Television Network', 'Shueisha']   \n",
       "2  ['Production I.G', 'Dentsu', 'Mainichi Broadca...   \n",
       "3  ['Frontier Works', 'Media Factory', 'Kadokawa ...   \n",
       "4  ['Shochiku', 'Pony Canyon', 'Kodansha', 'ABC A...   \n",
       "\n",
       "                                            synopsis  \\\n",
       "0  After a horrific alchemy experiment goes wrong...   \n",
       "1  Hunters devote themselves to accomplishing haz...   \n",
       "2  Seeking to restore humanity's diminishing hope...   \n",
       "3  Eccentric scientist Rintarou Okabe has a never...   \n",
       "4  As a wild youth, elementary school student Sho...   \n",
       "\n",
       "                      title_english              title_japanese  is_anime  \n",
       "0  Fullmetal Alchemist: Brotherhood  鋼の錬金術師 FULLMETAL ALCHEMIST         1  \n",
       "1                   Hunter x Hunter    HUNTER×HUNTER（ハンター×ハンター）         1  \n",
       "2   Attack on Titan Season 3 Part 2        進撃の巨人 Season3 Part.2         1  \n",
       "3                       Steins;Gate                 STEINS;GATE         1  \n",
       "4                    A Silent Voice                         聲の形         1  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.concat([df_anime_aligned, df_manga_aligned], ignore_index=True)\n",
    "\n",
    "#remove unnecessary common columns\n",
    "df_full = df_full.drop(columns=['real_start_date', 'real_end_date', 'volumes'])\n",
    "\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract year and month\n",
    "def extract_year_and_month(date):\n",
    "    try:\n",
    "        # Convert the date string to a datetime object\n",
    "        datetime_date = pd.to_datetime(date, errors='raise')\n",
    "        # Extract year and month\n",
    "        return datetime_date.year, datetime_date.month\n",
    "    except:\n",
    "        # return NaN if fails\n",
    "        return np.nan, np.nan\n",
    "    \n",
    "# Apply the function to the 'start_date' column\n",
    "df_full[['start_year', 'start_month']] = df_full['start_date'].apply(lambda x: pd.Series(extract_year_and_month(x)))\n",
    "\n",
    "# Apply the function to the 'end_date' column\n",
    "df_full[['end_year', 'end_month']] = df_full['end_date'].apply(lambda x: pd.Series(extract_year_and_month(x)))\n",
    "\n",
    "#remove useless columns\n",
    "df_full = df_full.drop(columns=['start_date', 'end_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_year</th>\n",
       "      <th>end_year</th>\n",
       "      <th>start_season</th>\n",
       "      <th>end_season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Summer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_year  end_year start_season end_season\n",
       "0      2009.0    2010.0       Spring     Summer\n",
       "1      2011.0    2014.0       Autumn     Summer\n",
       "2      2019.0    2019.0       Spring     Summer\n",
       "3      2011.0    2011.0       Spring     Summer\n",
       "4      2016.0    2016.0       Summer     Summer"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to transform Start or End month into season refer to Events of Anime\n",
    "def month_to_season(month):\n",
    "    # If the data is in range, return corresponding Season of events of Anime\n",
    "    if month in [1, 2, 3]:\n",
    "        return 'Winter'\n",
    "    elif month in [4, 5, 6]:\n",
    "        return 'Spring'\n",
    "    elif month in [7, 8, 9]:\n",
    "        return 'Summer'\n",
    "    elif month in [10, 11, 12]:\n",
    "        return 'Autumn'\n",
    "    else:\n",
    "        return np.nan  # Handle unexpected cases, though this shouldn't occur with valid months\n",
    "\n",
    "# Apply the function to transform the month value to season categories\n",
    "df_full['start_season'] = df_full['start_month'].apply(month_to_season)\n",
    "df_full['end_season'] = df_full['end_month'].apply(month_to_season)\n",
    "\n",
    "#remove useless columns\n",
    "df_full = df_full.drop(columns=['start_month', 'end_month'])\n",
    "\n",
    "#Check for Year and Season feature\n",
    "df_full[['start_year', 'end_year', 'start_season', 'end_season']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in train set:  19453\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df_full, test_size=0.2, random_state=RANDOM_SEED)\n",
    "print('Number of rows in train set: ', len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing data in Training Set:\n",
      "\n",
      "title                    0\n",
      "type                     7\n",
      "score                 5969\n",
      "scored_by                0\n",
      "status                   0\n",
      "episodes/chapters     3887\n",
      "source               12989\n",
      "members                  0\n",
      "favorites                0\n",
      "sfw                      0\n",
      "approved                 0\n",
      "genres                   0\n",
      "themes                   0\n",
      "demographics             0\n",
      "creators                 0\n",
      "production_source        0\n",
      "synopsis                 0\n",
      "title_english            0\n",
      "title_japanese           0\n",
      "is_anime                 0\n",
      "start_year             328\n",
      "end_year              3478\n",
      "start_season           328\n",
      "end_season            3478\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check for missing data \n",
    "print(\"Number of missing data in Training Set:\\n\")\n",
    "print(train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing data in Testing Set:\n",
      "\n",
      "title                   0\n",
      "type                    1\n",
      "score                1494\n",
      "scored_by               0\n",
      "status                  0\n",
      "episodes/chapters     970\n",
      "start_date             75\n",
      "end_date              875\n",
      "source               3239\n",
      "members                 0\n",
      "favorites               0\n",
      "sfw                     0\n",
      "approved                0\n",
      "genres                  0\n",
      "themes                  0\n",
      "demographics            0\n",
      "creators                0\n",
      "production_source       0\n",
      "synopsis                0\n",
      "title_english           0\n",
      "title_japanese          0\n",
      "is_anime                0\n",
      "start_year             75\n",
      "start_month            75\n",
      "end_year              875\n",
      "end_month             875\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check for missing data \n",
    "print(\"Number of missing data in Testing Set:\\n\")\n",
    "print(test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing data in Training Set:\n",
      "\n",
      "title                0\n",
      "type                 0\n",
      "score                0\n",
      "scored_by            0\n",
      "status               0\n",
      "episodes/chapters    0\n",
      "source               0\n",
      "members              0\n",
      "favorites            0\n",
      "sfw                  0\n",
      "approved             0\n",
      "genres               0\n",
      "themes               0\n",
      "demographics         0\n",
      "creators             0\n",
      "production_source    0\n",
      "synopsis             0\n",
      "title_english        0\n",
      "title_japanese       0\n",
      "is_anime             0\n",
      "start_year           0\n",
      "end_year             0\n",
      "start_season         0\n",
      "end_season           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Non-numerical columns\n",
    "Non_Numerical = ['type', 'source', 'start_season', 'end_season']\n",
    "\n",
    "# Create an imputer for non-numerical data filling with 'Missing'\n",
    "categorical_imputer = SimpleImputer(strategy='constant', fill_value='Missing')\n",
    "\n",
    "# Impute non-numerical columns\n",
    "train[Non_Numerical] = categorical_imputer.fit_transform(train[Non_Numerical])\n",
    "\n",
    "# Numerical columns\n",
    "Numerical = ['score', 'scored_by', 'episodes/chapters', 'members', 'favorites', 'start_year' , 'end_year']\n",
    "\n",
    "# Create an imputer for numerical data using KNNImputer\n",
    "knn_imputer = KNNImputer(n_neighbors=3)\n",
    "\n",
    "# Impute numerical columns\n",
    "train[Numerical] = knn_imputer.fit_transform(train[Numerical])\n",
    "\n",
    "# Check for result\n",
    "print(\"Number of missing data in Training Set:\\n\")\n",
    "print(train.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>score</th>\n",
       "      <th>scored_by</th>\n",
       "      <th>status</th>\n",
       "      <th>episodes/chapters</th>\n",
       "      <th>source</th>\n",
       "      <th>members</th>\n",
       "      <th>favorites</th>\n",
       "      <th>sfw</th>\n",
       "      <th>approved</th>\n",
       "      <th>genres</th>\n",
       "      <th>themes</th>\n",
       "      <th>demographics</th>\n",
       "      <th>creators</th>\n",
       "      <th>production_source</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>title_english</th>\n",
       "      <th>title_japanese</th>\n",
       "      <th>is_anime</th>\n",
       "      <th>start_season</th>\n",
       "      <th>end_season</th>\n",
       "      <th>elapsed_start_time</th>\n",
       "      <th>elapsed_end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13870</th>\n",
       "      <td>Souzai Saishuka no Isekai Ryokouki</td>\n",
       "      <td>manga</td>\n",
       "      <td>6.530000</td>\n",
       "      <td>-0.178503</td>\n",
       "      <td>currently_publishing</td>\n",
       "      <td>-0.285907</td>\n",
       "      <td>Missing</td>\n",
       "      <td>-0.185451</td>\n",
       "      <td>-0.111569</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>['Adventure', 'Fantasy']</td>\n",
       "      <td>['Isekai', 'Reincarnation']</td>\n",
       "      <td>[]</td>\n",
       "      <td>Tomozo, Masuo Kinoko</td>\n",
       "      <td>['AlphaPolis Web Manga']</td>\n",
       "      <td>Takeru Kamishiro is an ordinary middle aged sa...</td>\n",
       "      <td>A Gatherer's Adventure in Isekai</td>\n",
       "      <td>素材採取家の異世界旅行記</td>\n",
       "      <td>0</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Missing</td>\n",
       "      <td>100.0</td>\n",
       "      <td>92.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8825</th>\n",
       "      <td>Kingyo no Isshou</td>\n",
       "      <td>movie</td>\n",
       "      <td>6.583333</td>\n",
       "      <td>-0.202222</td>\n",
       "      <td>finished_airing</td>\n",
       "      <td>-0.462556</td>\n",
       "      <td>original</td>\n",
       "      <td>-0.236163</td>\n",
       "      <td>-0.114968</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>['Slice of Life']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>An elementary school student named Mitsui won ...</td>\n",
       "      <td>Short and Happy Life of a Goldfish</td>\n",
       "      <td>金魚の一生</td>\n",
       "      <td>1</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Winter</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6178</th>\n",
       "      <td>Takara-sagashi</td>\n",
       "      <td>movie</td>\n",
       "      <td>6.170000</td>\n",
       "      <td>-0.199299</td>\n",
       "      <td>finished_airing</td>\n",
       "      <td>-0.462556</td>\n",
       "      <td>picture_book</td>\n",
       "      <td>-0.224216</td>\n",
       "      <td>-0.114968</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>['Adventure', 'Fantasy']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Kids']</td>\n",
       "      <td>['Studio Ghibli']</td>\n",
       "      <td>[]</td>\n",
       "      <td>Short film shown only in the Ghibli Museum in ...</td>\n",
       "      <td>Treasure Hunting</td>\n",
       "      <td>たからさがし</td>\n",
       "      <td>1</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Spring</td>\n",
       "      <td>94.0</td>\n",
       "      <td>94.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5372</th>\n",
       "      <td>Nakedyouth</td>\n",
       "      <td>ona</td>\n",
       "      <td>5.690000</td>\n",
       "      <td>-0.162739</td>\n",
       "      <td>finished_airing</td>\n",
       "      <td>-0.462556</td>\n",
       "      <td>original</td>\n",
       "      <td>-0.187413</td>\n",
       "      <td>-0.112969</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>['Boys Love', 'Romance', 'Slice of Life', 'Spo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Kojiro Shishido Animation Works']</td>\n",
       "      <td>In Nakedyouth, Shishido takes us on a journey ...</td>\n",
       "      <td>Naked Youth</td>\n",
       "      <td>Nakedyouth</td>\n",
       "      <td>1</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Winter</td>\n",
       "      <td>89.0</td>\n",
       "      <td>89.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15978</th>\n",
       "      <td>Yu☆Gi☆Oh! GX Tokubetsu-hen</td>\n",
       "      <td>one_shot</td>\n",
       "      <td>6.550000</td>\n",
       "      <td>-0.197994</td>\n",
       "      <td>finished</td>\n",
       "      <td>-0.462556</td>\n",
       "      <td>Missing</td>\n",
       "      <td>-0.230989</td>\n",
       "      <td>-0.114568</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>['Adventure', 'Comedy', 'Fantasy']</td>\n",
       "      <td>['School', 'Strategy Game']</td>\n",
       "      <td>['Shounen']</td>\n",
       "      <td>Kazuki Takahashi, Naoyuki Kageyama</td>\n",
       "      <td>['V-Jump']</td>\n",
       "      <td>A special one-shot released in commemoration o...</td>\n",
       "      <td>Yu-Gi-Oh! GX</td>\n",
       "      <td>遊☆戯☆王GX特別編</td>\n",
       "      <td>0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Spring</td>\n",
       "      <td>97.0</td>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    title      type     score  scored_by  \\\n",
       "13870  Souzai Saishuka no Isekai Ryokouki     manga  6.530000  -0.178503   \n",
       "8825                     Kingyo no Isshou     movie  6.583333  -0.202222   \n",
       "6178                       Takara-sagashi     movie  6.170000  -0.199299   \n",
       "5372                           Nakedyouth       ona  5.690000  -0.162739   \n",
       "15978          Yu☆Gi☆Oh! GX Tokubetsu-hen  one_shot  6.550000  -0.197994   \n",
       "\n",
       "                     status  episodes/chapters        source   members  \\\n",
       "13870  currently_publishing          -0.285907       Missing -0.185451   \n",
       "8825        finished_airing          -0.462556      original -0.236163   \n",
       "6178        finished_airing          -0.462556  picture_book -0.224216   \n",
       "5372        finished_airing          -0.462556      original -0.187413   \n",
       "15978              finished          -0.462556       Missing -0.230989   \n",
       "\n",
       "       favorites   sfw  approved  \\\n",
       "13870  -0.111569  True      True   \n",
       "8825   -0.114968  True      True   \n",
       "6178   -0.114968  True      True   \n",
       "5372   -0.112969  True      True   \n",
       "15978  -0.114568  True      True   \n",
       "\n",
       "                                                  genres  \\\n",
       "13870                           ['Adventure', 'Fantasy']   \n",
       "8825                                   ['Slice of Life']   \n",
       "6178                            ['Adventure', 'Fantasy']   \n",
       "5372   ['Boys Love', 'Romance', 'Slice of Life', 'Spo...   \n",
       "15978                 ['Adventure', 'Comedy', 'Fantasy']   \n",
       "\n",
       "                            themes demographics  \\\n",
       "13870  ['Isekai', 'Reincarnation']           []   \n",
       "8825                            []           []   \n",
       "6178                            []     ['Kids']   \n",
       "5372                            []           []   \n",
       "15978  ['School', 'Strategy Game']  ['Shounen']   \n",
       "\n",
       "                                 creators  \\\n",
       "13870                Tomozo, Masuo Kinoko   \n",
       "8825                                   []   \n",
       "6178                    ['Studio Ghibli']   \n",
       "5372                                   []   \n",
       "15978  Kazuki Takahashi, Naoyuki Kageyama   \n",
       "\n",
       "                         production_source  \\\n",
       "13870             ['AlphaPolis Web Manga']   \n",
       "8825                                    []   \n",
       "6178                                    []   \n",
       "5372   ['Kojiro Shishido Animation Works']   \n",
       "15978                           ['V-Jump']   \n",
       "\n",
       "                                                synopsis  \\\n",
       "13870  Takeru Kamishiro is an ordinary middle aged sa...   \n",
       "8825   An elementary school student named Mitsui won ...   \n",
       "6178   Short film shown only in the Ghibli Museum in ...   \n",
       "5372   In Nakedyouth, Shishido takes us on a journey ...   \n",
       "15978  A special one-shot released in commemoration o...   \n",
       "\n",
       "                            title_english title_japanese  is_anime  \\\n",
       "13870    A Gatherer's Adventure in Isekai   素材採取家の異世界旅行記         0   \n",
       "8825   Short and Happy Life of a Goldfish          金魚の一生         1   \n",
       "6178                     Treasure Hunting         たからさがし         1   \n",
       "5372                          Naked Youth     Nakedyouth         1   \n",
       "15978                        Yu-Gi-Oh! GX     遊☆戯☆王GX特別編         0   \n",
       "\n",
       "      start_season end_season  elapsed_start_time   elapsed_end_time   \n",
       "13870       Autumn    Missing                100.0          92.333333  \n",
       "8825        Winter     Winter                 76.0          76.000000  \n",
       "6178        Spring     Spring                 94.0          94.000000  \n",
       "5372        Winter     Winter                 89.0          89.000000  \n",
       "15978       Spring     Spring                 97.0          97.000000  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Selecting columns to normalize\n",
    "columns_to_normalize = [\"scored_by\", \"episodes/chapters\", \"members\", \"favorites\"]\n",
    "\n",
    "earliest_start_year = train['start_year'].min()\n",
    "\n",
    "# function for Normalizing the selected columns\n",
    "def Normalizing(data):\n",
    "    data_normalized = data.copy()\n",
    "    data_normalized[columns_to_normalize] = scaler.fit_transform(train[columns_to_normalize])\n",
    "\n",
    "    # Calculate the duration by subtracting the earliest start year from all years\n",
    "    data_normalized['elapsed_start_time '] = data_normalized['start_year'] - earliest_start_year\n",
    "    data_normalized['elapsed_end_time '] = data_normalized['end_year'] - earliest_start_year\n",
    "\n",
    "    data_normalized = data_normalized.drop(columns=['start_year', 'end_year'])\n",
    "\n",
    "    return data_normalized\n",
    "\n",
    "train_normalized = Normalizing(train)\n",
    "train_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization and lemmatization by keeping `{'NOUN', 'VERB', 'ADJ', 'PROPN', 'ADV'}` and replace named entity with place holder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after filtering empty token:  19309\n"
     ]
    }
   ],
   "source": [
    "# tokenization and lemmatization\n",
    "import spacy\n",
    "\n",
    "POS_TO_KEEP = {'NOUN', 'VERB', 'ADJ', 'PROPN', 'ADV'}\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "stop_words = nlp.Defaults.stop_words\n",
    "\n",
    "def tokenization(doc):\n",
    "    \"\"\"\n",
    "    Filter out number.\n",
    "    Replace person, organization, and location entities with '<ent_type_>'\n",
    "    Return lemma if its POS is in `POS_TO_KEEP` and not in stop_words.\n",
    "    \"\"\"\n",
    "    tokens = []\n",
    "\n",
    "    for token in doc:\n",
    "        if token.is_digit:\n",
    "            # filter out numeric tokens\n",
    "            continue\n",
    "\n",
    "        if token.ent_type_ in ['PERSON', 'ORG', 'GPE']:\n",
    "            # replace person, organization, and location entities\n",
    "            tokens.append(f'<{token.ent_type_}>')\n",
    "            \n",
    "        elif token.pos_ in POS_TO_KEEP and not token.lemma_ in stop_words:\n",
    "            # return lemma if its POS is in `POS_TO_KEEP` and not in stop_words\n",
    "            tokens.append(token.lemma_)\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# use nlp.pipe for batch processing\n",
    "train['title_en_token'] = [\n",
    "    tokenization(doc) for doc in nlp.pipe(train['title_english'], batch_size=100, n_process=-1)\n",
    "]\n",
    "train['synopsis_token'] = [\n",
    "    tokenization(doc) for doc in nlp.pipe(train['synopsis'], batch_size=100, n_process=-1)\n",
    "]\n",
    "\n",
    "# filter out empty token\n",
    "train = train[train['title_en_token'].apply(lambda x: len(x) > 0) & train['synopsis_token'].apply(lambda x: len(x) > 0)] # both columns cannot be empty\n",
    "\n",
    "print('Number of rows after filtering empty token: ', len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_english</th>\n",
       "      <th>title_en_token</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>synopsis_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16373</th>\n",
       "      <td>Marked By King Bs</td>\n",
       "      <td>[Marked, King, Bs]</td>\n",
       "      <td>High school is hard enough without a target on your back, but that's exactly the situation Annie finds herself in when she crosses a group of the most popular kids in school. Marked by the king bee himself, the notorious Ashton Griffin, Annie becomes his newest fixation—and he is determined to make her life miserable. Now at his beck and call, Annie must stay on Ashton's good side to maintain her peaceful life and avoid becoming a social pariah. As she navigates her way through alienating social cliques, persistent old crushes, and the hot upstairs neighbor who never puts a shirt on, Annie will soon learn that there's more to being popular than meets the eye. She just wanted to live a normal life, but maybe there's no escaping these king bees.\\r\\n\\r\\n</td>\n",
       "      <td>[high, school, hard, target, exactly, situation, &lt;PERSON&gt;, find, cross, group, popular, kid, school, mark, king, bee, notorious, &lt;PERSON&gt;, &lt;PERSON&gt;, &lt;PERSON&gt;, new, fixation, determined, life, miserable, beck, &lt;PERSON&gt;, stay, &lt;ORG&gt;, good, maintain, peaceful, life, avoid, social, pariah, navigate, way, alienate, social, clique, persistent, old, crush, hot, upstairs, neighbor, shirt, &lt;PERSON&gt;, soon, learn, popular, meet, eye, want, live, normal, life, maybe, escape, king, bee]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           title_english      title_en_token  \\\n",
       "16373  Marked By King Bs  [Marked, King, Bs]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        synopsis  \\\n",
       "16373  High school is hard enough without a target on your back, but that's exactly the situation Annie finds herself in when she crosses a group of the most popular kids in school. Marked by the king bee himself, the notorious Ashton Griffin, Annie becomes his newest fixation—and he is determined to make her life miserable. Now at his beck and call, Annie must stay on Ashton's good side to maintain her peaceful life and avoid becoming a social pariah. As she navigates her way through alienating social cliques, persistent old crushes, and the hot upstairs neighbor who never puts a shirt on, Annie will soon learn that there's more to being popular than meets the eye. She just wanted to live a normal life, but maybe there's no escaping these king bees.\\r\\n\\r\\n   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       synopsis_token  \n",
       "16373  [high, school, hard, target, exactly, situation, <PERSON>, find, cross, group, popular, kid, school, mark, king, bee, notorious, <PERSON>, <PERSON>, <PERSON>, new, fixation, determined, life, miserable, beck, <PERSON>, stay, <ORG>, good, maintain, peaceful, life, avoid, social, pariah, navigate, way, alienate, social, clique, persistent, old, crush, hot, upstairs, neighbor, shirt, <PERSON>, soon, learn, popular, meet, eye, want, live, normal, life, maybe, escape, king, bee]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# review tokenization\n",
    "with pd.option_context('display.max_colwidth', None):\n",
    "    display(train[['title_english', 'title_en_token', 'synopsis', 'synopsis_token']].sample(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since titles and synopses play different roles (titles are short and often genre-indicative, while synopses provide detailed content descriptions), we use two separate vectorizers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Titles are shorter and often contain rare, context-rich words that are crucial for capturing unique meaning, while synopses are longer and contain more common words, making them less reliant on capturing rare vocabulary. So, we use a higher `max_features` or `vector_size` for title to ensures it capture these niche terms and their relationships, while use lower for synopsis to focus on the more frequently relevant words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# initialize title tfidf\n",
    "tfidf_title = TfidfVectorizer(\n",
    "    ngram_range=(1,1),  # uni-gram\n",
    "    min_df=1,           # don't filter rare words as they are important for title\n",
    "    max_df=0.8,         # filter out very common words\n",
    ")\n",
    "\n",
    "# initialize synopsis tfidf\n",
    "tfidf_synopsis = TfidfVectorizer(\n",
    "    ngram_range=(1,2),  # uni-gram or bi-gram\n",
    "    max_features=2000,  # focus on the more frequently relevant words\n",
    "    min_df=2,           # filter out extremely rare words\n",
    "    max_df=0.8,         # filter out very common words\n",
    ")\n",
    "\n",
    "# train tfidf\n",
    "title_en_tfidf_matrix = tfidf_title.fit_transform(train['title_en_token'].apply(lambda x: \" \".join(x)))\n",
    "synopsis_tfidf_matrix = tfidf_synopsis.fit_transform(train['synopsis_token'].apply(lambda x: \" \".join(x)))\n",
    "\n",
    "# add result to train df\n",
    "train['title_en_tfidf'] = [title_en_tfidf_matrix[i] for i in range(title_en_tfidf_matrix.shape[0])]\n",
    "train['synopsis_tfidf'] = [synopsis_tfidf_matrix[i] for i in range(synopsis_tfidf_matrix.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For word embedding, we choose **Word2Vec - Skip-gram** because it tends to capture rare words more effectively (e.g. niche anime/manga-specific vocabulary), comparing to Word2Vec - CBOW and GloVe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word embedding\n",
    "import multiprocessing\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# dynamically determine the number of CPU cores\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "\n",
    "# train title skipgram model\n",
    "skipgram_model_title = Word2Vec(\n",
    "    train['title_en_token'].tolist(),\n",
    "    sg=1,               # skip-gram\n",
    "    vector_size=300,    # title use higher dim\n",
    "    window=2,           # title use smaller window size\n",
    "    min_count=1,        # titles may contain rare but important words\n",
    "    epochs=30,          # title are shorter, need more epochs to train\n",
    "    workers=num_workers,\n",
    "    seed=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# train synopsis skipgram model\n",
    "skipgram_model_synopsis = Word2Vec(\n",
    "    train['synopsis_token'].tolist(),\n",
    "    sg=1,               # skip-gram\n",
    "    vector_size=150,    # synopsis use lower dim\n",
    "    window=5,           # synopsis use larger window size\n",
    "    min_count=2,        # filter out extremely rare words\n",
    "    epochs=15,\n",
    "    workers=num_workers,\n",
    "    seed=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# clean tokens that does not exist in the skipgram vocab (because of `min_count`)\n",
    "model_vocab = set(skipgram_model_synopsis.wv.index_to_key)\n",
    "train['synopsis_token'] = train['synopsis_token'].apply(lambda x: [token for token in x if token in model_vocab])\n",
    "train = train[train['synopsis_token'].apply(lambda x: len(x) > 0)]  # filter out empty entry after clean tokens\n",
    "\n",
    "# apply skipgram model\n",
    "train['title_en_skipgram'] = train['title_en_token'].apply(lambda x: skipgram_model_title.wv[x])\n",
    "train['synopsis_skipgram'] = train['synopsis_token'].apply(lambda x: skipgram_model_synopsis.wv[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_japanese</th>\n",
       "      <th>title_english</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>title_en_tfidf</th>\n",
       "      <th>title_en_skipgram</th>\n",
       "      <th>synopsis_tfidf</th>\n",
       "      <th>synopsis_skipgram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23943</th>\n",
       "      <td>愛を知った一週間</td>\n",
       "      <td>Chosen As The Frenchman's Bride</td>\n",
       "      <td>After losing her father at a young age, Jane g...</td>\n",
       "      <td>(0, 5365)\\t0.20308269236008522\\n  (0, 1298)\\...</td>\n",
       "      <td>[[-0.050672267, -0.07246053, 0.14060606, -0.11...</td>\n",
       "      <td>(0, 1990)\\t0.12745880457602696\\n  (0, 969)\\t...</td>\n",
       "      <td>[[0.37020886, 0.024892427, -0.081325725, -0.54...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20488</th>\n",
       "      <td>ふたりぽっち</td>\n",
       "      <td>The Two Daughters</td>\n",
       "      <td>Kaoru has to stay with Reiko's family, a girl ...</td>\n",
       "      <td>(0, 1793)\\t1.0</td>\n",
       "      <td>[[-0.03223555, -0.11463614, 0.18719757, -0.009...</td>\n",
       "      <td>(0, 1224)\\t0.26511441322114115\\n  (0, 523)\\t...</td>\n",
       "      <td>[[-0.05985926, 0.18823454, -0.102404416, -0.12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12351</th>\n",
       "      <td>奪う者 奪われる者</td>\n",
       "      <td>Bereave or Bereaved</td>\n",
       "      <td>Seto Yu is a 12-year-old boy, despite being ve...</td>\n",
       "      <td>(0, 731)\\t0.7071067811865476\\n  (0, 732)\\t0....</td>\n",
       "      <td>[[-0.009359805, -0.022338165, 0.03214639, -0.0...</td>\n",
       "      <td>(0, 1968)\\t0.12348505189125379\\n  (0, 162)\\t...</td>\n",
       "      <td>[[-0.05985926, 0.18823454, -0.102404416, -0.12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23146</th>\n",
       "      <td>まんがグリム童話 血と悦楽に溺れた実在姫君たち</td>\n",
       "      <td>Real Princess who Indulge in Blood &amp; Lust</td>\n",
       "      <td>1-2. Last Emperor no Tsuma: Enyou Kougou\\r\\n3....</td>\n",
       "      <td>(0, 5365)\\t0.5041341482361837\\n  (0, 5886)\\t...</td>\n",
       "      <td>[[-0.02228411, -0.12334833, 0.120474376, -0.08...</td>\n",
       "      <td>(0, 1224)\\t0.6939879716446256\\n  (0, 1290)\\t...</td>\n",
       "      <td>[[-0.17345911, 0.00636432, -0.08250168, -0.332...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2815</th>\n",
       "      <td>王ドロボウ JING in Seventh Heaven</td>\n",
       "      <td>Jing: King of Bandits - Seventh Heaven</td>\n",
       "      <td>Jing, the infamous King of Bandits, finds hims...</td>\n",
       "      <td>(0, 4020)\\t0.31691060798982196\\n  (0, 3364)\\...</td>\n",
       "      <td>[[-0.03958812, -0.035999063, 0.12214554, 4.222...</td>\n",
       "      <td>(0, 1968)\\t0.11052129494573408\\n  (0, 1152)\\...</td>\n",
       "      <td>[[0.051790062, 0.025802549, -0.02216094, -0.11...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title_japanese  \\\n",
       "23943                      愛を知った一週間   \n",
       "20488                        ふたりぽっち   \n",
       "12351                     奪う者 奪われる者   \n",
       "23146       まんがグリム童話 血と悦楽に溺れた実在姫君たち   \n",
       "2815   王ドロボウ JING in Seventh Heaven   \n",
       "\n",
       "                                   title_english  \\\n",
       "23943            Chosen As The Frenchman's Bride   \n",
       "20488                          The Two Daughters   \n",
       "12351                        Bereave or Bereaved   \n",
       "23146  Real Princess who Indulge in Blood & Lust   \n",
       "2815      Jing: King of Bandits - Seventh Heaven   \n",
       "\n",
       "                                                synopsis  \\\n",
       "23943  After losing her father at a young age, Jane g...   \n",
       "20488  Kaoru has to stay with Reiko's family, a girl ...   \n",
       "12351  Seto Yu is a 12-year-old boy, despite being ve...   \n",
       "23146  1-2. Last Emperor no Tsuma: Enyou Kougou\\r\\n3....   \n",
       "2815   Jing, the infamous King of Bandits, finds hims...   \n",
       "\n",
       "                                          title_en_tfidf  \\\n",
       "23943    (0, 5365)\\t0.20308269236008522\\n  (0, 1298)\\...   \n",
       "20488                                     (0, 1793)\\t1.0   \n",
       "12351    (0, 731)\\t0.7071067811865476\\n  (0, 732)\\t0....   \n",
       "23146    (0, 5365)\\t0.5041341482361837\\n  (0, 5886)\\t...   \n",
       "2815     (0, 4020)\\t0.31691060798982196\\n  (0, 3364)\\...   \n",
       "\n",
       "                                       title_en_skipgram  \\\n",
       "23943  [[-0.050672267, -0.07246053, 0.14060606, -0.11...   \n",
       "20488  [[-0.03223555, -0.11463614, 0.18719757, -0.009...   \n",
       "12351  [[-0.009359805, -0.022338165, 0.03214639, -0.0...   \n",
       "23146  [[-0.02228411, -0.12334833, 0.120474376, -0.08...   \n",
       "2815   [[-0.03958812, -0.035999063, 0.12214554, 4.222...   \n",
       "\n",
       "                                          synopsis_tfidf  \\\n",
       "23943    (0, 1990)\\t0.12745880457602696\\n  (0, 969)\\t...   \n",
       "20488    (0, 1224)\\t0.26511441322114115\\n  (0, 523)\\t...   \n",
       "12351    (0, 1968)\\t0.12348505189125379\\n  (0, 162)\\t...   \n",
       "23146    (0, 1224)\\t0.6939879716446256\\n  (0, 1290)\\t...   \n",
       "2815     (0, 1968)\\t0.11052129494573408\\n  (0, 1152)\\...   \n",
       "\n",
       "                                       synopsis_skipgram  \n",
       "23943  [[0.37020886, 0.024892427, -0.081325725, -0.54...  \n",
       "20488  [[-0.05985926, 0.18823454, -0.102404416, -0.12...  \n",
       "12351  [[-0.05985926, 0.18823454, -0.102404416, -0.12...  \n",
       "23146  [[-0.17345911, 0.00636432, -0.08250168, -0.332...  \n",
       "2815   [[0.051790062, 0.025802549, -0.02216094, -0.11...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['title_japanese', 'title_english', 'synopsis', 'title_en_tfidf', 'title_en_skipgram', 'synopsis_tfidf', 'synopsis_skipgram']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export necessary assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['assets/skipgram_model_synopsis.joblib']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# train and test df\n",
    "joblib.dump(train, 'assets/train.joblib')\n",
    "joblib.dump(test, 'assets/test.joblib')\n",
    "\n",
    "# tfidf_matrix\n",
    "joblib.dump(title_en_tfidf_matrix, 'assets/title_en_tfidf_matrix.joblib')\n",
    "joblib.dump(synopsis_tfidf_matrix, 'assets/synopsis_tfidf_matrix.joblib')\n",
    "\n",
    "# tfidf vectorizer\n",
    "joblib.dump(tfidf_title, 'assets/tfidf_title_vectorizer.joblib')\n",
    "joblib.dump(tfidf_synopsis, 'assets/tfidf_synopsis_vectorizer.joblib')\n",
    "\n",
    "# skipgram\n",
    "joblib.dump(skipgram_model_title, 'assets/skipgram_model_title.joblib')\n",
    "joblib.dump(skipgram_model_synopsis, 'assets/skipgram_model_synopsis.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store library version\n",
    "# run every time before you commit\n",
    "!pip freeze > requirements.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env696",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
