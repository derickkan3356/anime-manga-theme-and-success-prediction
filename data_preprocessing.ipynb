{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\MADS\\696\\696\\env696\\Scripts\\python.exe\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\python.exe\n",
      "C:\\Users\\user\\AppData\\Local\\Microsoft\\WindowsApps\\python.exe\n"
     ]
    }
   ],
   "source": [
    "!where python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this code to make sure you install all the required libraries\n",
    "# be sure you are in virtual environment before install, otherwise it will overwrite your local environment\n",
    "\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "RANDOM_SEED = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anime = pd.read_csv(\"assets/anime.csv\")\n",
    "df_manga = pd.read_csv(\"assets/manga.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24985, 39), (64833, 30))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anime.shape, df_manga.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prepocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some short synopsis contain no information about the story of manga/title. This will introduce noise to our model. Therefore, we decide to remove those rows with extremely short synopsis.\n",
    "Example:\n",
    "- Second season of Mao Zhi Ming.\n",
    "- The second season of Shen Lan Qi Yu Wushuang Zhu.\n",
    "- Recap episode of Hakyuu Houshin Engi.\n",
    "- Fifth Season of Bungou Stray Dogs\n",
    "- 1-3. Ba_ku\\n4-5. Mephisto\n",
    "- An absurd film by Kuri Youji.\n",
    "- Included one-shot:\\nBougainvillea\n",
    "- A collection of oneshots by Nishida Higashi.\n",
    "- A movie adaptation of the TV series.\n",
    "- Short film by Kurosaka Keita.\n",
    "- Special episodes added to DVDs and Blu-rays.\n",
    "- Movie based on the 1996 TV anime with an original plot.\n",
    "- Third season of Yuan Long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned anime shape:  (8863, 21)\n",
      "cleaned manga shape:  (15454, 20)\n"
     ]
    }
   ],
   "source": [
    "def data_cleaning(input_anime, input_manga):\n",
    "    df_anime = input_anime.copy()\n",
    "    df_manga = input_manga.copy()\n",
    "\n",
    "    # remove unnecessary columns\n",
    "    df_anime = df_anime.drop(columns=['anime_id', 'total_duration', 'start_year', 'start_season', 'rating', 'main_picture', 'url', 'trailer_url', 'background', 'created_at', 'updated_at', 'episode_duration', 'broadcast_day', 'broadcast_time', 'licensors', 'title_synonyms', 'real_start_date', 'real_end_date'])\n",
    "    df_manga = df_manga.drop(columns=['manga_id', 'main_picture', 'url', 'background', 'created_at_before', 'updated_at', 'title_synonyms', 'volumes', 'real_start_date', 'real_end_date'])\n",
    "\n",
    "    # remove rows that are null in 'synopsis' and 'title', which are crucial for our project\n",
    "    df_anime.dropna(subset=['title', 'synopsis', 'title_english', 'title_japanese'], inplace=True)\n",
    "    df_manga.dropna(subset=['title', 'synopsis', 'title_english', 'title_japanese'], inplace=True)\n",
    "\n",
    "    # remove '(Sources:...)' from synopsis\n",
    "    df_anime['synopsis'] = df_anime['synopsis'].apply(lambda x: re.sub(r'\\(Source:.*\\)', '', x))\n",
    "    df_manga['synopsis'] = df_manga['synopsis'].apply(lambda x: re.sub(r'\\(Source:.*\\)', '', x))\n",
    "\n",
    "    # remove '[Written by ...]' from synopsis\n",
    "    df_anime['synopsis'] = df_anime['synopsis'].apply(lambda x: re.sub(r'\\[Written by.*\\]', '', x))\n",
    "    df_manga['synopsis'] = df_manga['synopsis'].apply(lambda x: re.sub(r'\\[Written by.*\\]', '', x))\n",
    "\n",
    "    # remove rows that have extreme short synopsis\n",
    "    df_anime = df_anime[df_anime['synopsis'].apply(lambda x: len(x) > 50)]\n",
    "    df_manga = df_manga[df_manga['synopsis'].apply(lambda x: len(x) > 50)]\n",
    "\n",
    "    print('cleaned anime shape: ', df_anime.shape)\n",
    "    print('cleaned manga shape: ', df_manga.shape)\n",
    "\n",
    "    return df_anime, df_manga\n",
    "\n",
    "df_anime_cleaned, df_manga_cleaned = data_cleaning(df_anime, df_manga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anime extra columns: \n",
      " ['episodes', 'source', 'studios', 'producers']\n"
     ]
    }
   ],
   "source": [
    "print(\"anime extra columns: \\n\", [col for col in df_anime_cleaned.columns if not col in df_manga_cleaned.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manga extra columns: \n",
      " ['chapters', 'authors', 'serializations']\n"
     ]
    }
   ],
   "source": [
    "print(\"manga extra columns: \\n\", [col for col in df_manga_cleaned.columns if not col in df_anime_cleaned.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common columns: \n",
      " ['title', 'type', 'score', 'scored_by', 'status', 'start_date', 'end_date', 'members', 'favorites', 'sfw', 'approved', 'genres', 'themes', 'demographics', 'synopsis', 'title_english', 'title_japanese']\n"
     ]
    }
   ],
   "source": [
    "print(\"common columns: \\n\", [col for col in df_anime_cleaned.columns if col in df_manga_cleaned.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def extract_author_name(author_list):\n",
    "    try:\n",
    "        author_list = ast.literal_eval(author_list)\n",
    "        \n",
    "        # Extract first and last names of authors, ignoring the others\n",
    "        author_names = [f\"{author['first_name']} {author['last_name']}\".strip() for author in author_list if author['first_name'] or author['last_name']]\n",
    "        \n",
    "        # Join names for multiple authors\n",
    "        return ', '.join(author_names) if author_names else \"Missing\"\n",
    "    \n",
    "    except (ValueError, SyntaxError, KeyError, TypeError):\n",
    "        # Handle Missing data\n",
    "        return \"Missing\"\n",
    "\n",
    "# Apply the function to the 'authors' column\n",
    "def authors_extraction(input_manga):\n",
    "    df_manga = input_manga.copy()\n",
    "    df_manga['authors'] = df_manga['authors'].apply(extract_author_name)\n",
    "\n",
    "    return df_manga\n",
    "\n",
    "df_manga_extracted = authors_extraction(df_manga_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"[{'id': 1868, 'first_name': 'Kentarou', 'last_name': 'Miura', 'role': 'Story & Art'}, {'id': 49592, 'first_name': '', 'last_name': 'Studio Gaga', 'role': 'Art'}]\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_manga_cleaned['authors'].head(1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Kentarou Miura, Studio Gaga'], dtype=object)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_manga_extracted['authors'].head(1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra columns alignment**:\n",
    "| anime columns | manga columns | strategy |\n",
    "| --- | --- | --- |\n",
    "| episodes | chapters | episodes/chapters |\n",
    "| source | NULL | impute const 'Missing' |\n",
    "| studios | authors | creators |\n",
    "| producers | serializations | production_source |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_alignment(input_anime, input_manga):\n",
    "    df_anime = input_anime.copy()\n",
    "    df_manga = input_manga.copy()\n",
    "\n",
    "    # treat 'episodes' and 'chapters' the same, create null value for 'volume' in anime\n",
    "    df_anime.rename(columns={'episodes': 'episodes/chapters'}, inplace=True)\n",
    "    df_manga.rename(columns={'chapters': 'episodes/chapters'}, inplace=True)\n",
    "\n",
    "    # Combine studios and authors together to get creators columns\n",
    "    df_anime.rename(columns={'studios': 'creators'}, inplace=True)\n",
    "    df_manga.rename(columns={'authors': 'creators'}, inplace=True)\n",
    "\n",
    "    # Also for producers and serialization\n",
    "    df_anime.rename(columns={'producers': 'production_source'}, inplace=True)\n",
    "    df_manga.rename(columns={'serializations': 'production_source'}, inplace=True)\n",
    "\n",
    "    # To distinguish where the data from\n",
    "    df_anime['is_anime'] = 1\n",
    "    df_manga['is_anime'] = 0 \n",
    "    \n",
    "    return df_anime, df_manga\n",
    "\n",
    "df_anime_aligned, df_manga_aligned = columns_alignment(df_anime_cleaned, df_manga_extracted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94875cc3",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"><b><<<<<<< local</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>score</th>\n",
       "      <th>scored_by</th>\n",
       "      <th>status</th>\n",
       "      <th>episodes/chapters</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>source</th>\n",
       "      <th>members</th>\n",
       "      <th>favorites</th>\n",
       "      <th>sfw</th>\n",
       "      <th>approved</th>\n",
       "      <th>genres</th>\n",
       "      <th>themes</th>\n",
       "      <th>demographics</th>\n",
       "      <th>creators</th>\n",
       "      <th>production_source</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>title_english</th>\n",
       "      <th>title_japanese</th>\n",
       "      <th>is_anime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>tv</td>\n",
       "      <td>9.10</td>\n",
       "      <td>2037075</td>\n",
       "      <td>finished_airing</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2009-04-05</td>\n",
       "      <td>2010-07-04</td>\n",
       "      <td>manga</td>\n",
       "      <td>3206028</td>\n",
       "      <td>219036</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>['Action', 'Adventure', 'Drama', 'Fantasy']</td>\n",
       "      <td>['Military']</td>\n",
       "      <td>['Shounen']</td>\n",
       "      <td>['Bones']</td>\n",
       "      <td>['Aniplex', 'Square Enix', 'Mainichi Broadcast...</td>\n",
       "      <td>After a horrific alchemy experiment goes wrong...</td>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>鋼の錬金術師 FULLMETAL ALCHEMIST</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hunter x Hunter (2011)</td>\n",
       "      <td>tv</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1671587</td>\n",
       "      <td>finished_airing</td>\n",
       "      <td>148.0</td>\n",
       "      <td>2011-10-02</td>\n",
       "      <td>2014-09-24</td>\n",
       "      <td>manga</td>\n",
       "      <td>2688079</td>\n",
       "      <td>202109</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>['Action', 'Adventure', 'Fantasy']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Shounen']</td>\n",
       "      <td>['Madhouse']</td>\n",
       "      <td>['VAP', 'Nippon Television Network', 'Shueisha']</td>\n",
       "      <td>Hunters devote themselves to accomplishing haz...</td>\n",
       "      <td>Hunter x Hunter</td>\n",
       "      <td>HUNTER×HUNTER（ハンター×ハンター）</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shingeki no Kyojin Season 3 Part 2</td>\n",
       "      <td>tv</td>\n",
       "      <td>9.05</td>\n",
       "      <td>1491491</td>\n",
       "      <td>finished_airing</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2019-04-29</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>manga</td>\n",
       "      <td>2133927</td>\n",
       "      <td>55644</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>['Action', 'Drama']</td>\n",
       "      <td>['Gore', 'Military', 'Survival']</td>\n",
       "      <td>['Shounen']</td>\n",
       "      <td>['Wit Studio']</td>\n",
       "      <td>['Production I.G', 'Dentsu', 'Mainichi Broadca...</td>\n",
       "      <td>Seeking to restore humanity's diminishing hope...</td>\n",
       "      <td>Attack on Titan Season 3 Part 2</td>\n",
       "      <td>進撃の巨人 Season3 Part.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Steins;Gate</td>\n",
       "      <td>tv</td>\n",
       "      <td>9.07</td>\n",
       "      <td>1348232</td>\n",
       "      <td>finished_airing</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2011-04-06</td>\n",
       "      <td>2011-09-14</td>\n",
       "      <td>visual_novel</td>\n",
       "      <td>2463954</td>\n",
       "      <td>184312</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>['Drama', 'Sci-Fi', 'Suspense']</td>\n",
       "      <td>['Psychological', 'Time Travel']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['White Fox']</td>\n",
       "      <td>['Frontier Works', 'Media Factory', 'Kadokawa ...</td>\n",
       "      <td>Eccentric scientist Rintarou Okabe has a never...</td>\n",
       "      <td>Steins;Gate</td>\n",
       "      <td>STEINS;GATE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Koe no Katachi</td>\n",
       "      <td>movie</td>\n",
       "      <td>8.94</td>\n",
       "      <td>1540277</td>\n",
       "      <td>finished_airing</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-09-17</td>\n",
       "      <td>2016-09-17</td>\n",
       "      <td>manga</td>\n",
       "      <td>2218467</td>\n",
       "      <td>84124</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>['Award Winning', 'Drama']</td>\n",
       "      <td>['Romantic Subtext']</td>\n",
       "      <td>['Shounen']</td>\n",
       "      <td>['Kyoto Animation']</td>\n",
       "      <td>['Shochiku', 'Pony Canyon', 'Kodansha', 'ABC A...</td>\n",
       "      <td>As a wild youth, elementary school student Sho...</td>\n",
       "      <td>A Silent Voice</td>\n",
       "      <td>聲の形</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title   type  score  scored_by  \\\n",
       "0    Fullmetal Alchemist: Brotherhood     tv   9.10    2037075   \n",
       "1              Hunter x Hunter (2011)     tv   9.04    1671587   \n",
       "2  Shingeki no Kyojin Season 3 Part 2     tv   9.05    1491491   \n",
       "3                         Steins;Gate     tv   9.07    1348232   \n",
       "4                      Koe no Katachi  movie   8.94    1540277   \n",
       "\n",
       "            status  episodes/chapters  start_date    end_date        source  \\\n",
       "0  finished_airing               64.0  2009-04-05  2010-07-04         manga   \n",
       "1  finished_airing              148.0  2011-10-02  2014-09-24         manga   \n",
       "2  finished_airing               10.0  2019-04-29  2019-07-01         manga   \n",
       "3  finished_airing               24.0  2011-04-06  2011-09-14  visual_novel   \n",
       "4  finished_airing                1.0  2016-09-17  2016-09-17         manga   \n",
       "\n",
       "   members  favorites   sfw  approved  \\\n",
       "0  3206028     219036  True      True   \n",
       "1  2688079     202109  True      True   \n",
       "2  2133927      55644  True      True   \n",
       "3  2463954     184312  True      True   \n",
       "4  2218467      84124  True      True   \n",
       "\n",
       "                                        genres  \\\n",
       "0  ['Action', 'Adventure', 'Drama', 'Fantasy']   \n",
       "1           ['Action', 'Adventure', 'Fantasy']   \n",
       "2                          ['Action', 'Drama']   \n",
       "3              ['Drama', 'Sci-Fi', 'Suspense']   \n",
       "4                   ['Award Winning', 'Drama']   \n",
       "\n",
       "                             themes demographics             creators  \\\n",
       "0                      ['Military']  ['Shounen']            ['Bones']   \n",
       "1                                []  ['Shounen']         ['Madhouse']   \n",
       "2  ['Gore', 'Military', 'Survival']  ['Shounen']       ['Wit Studio']   \n",
       "3  ['Psychological', 'Time Travel']           []        ['White Fox']   \n",
       "4              ['Romantic Subtext']  ['Shounen']  ['Kyoto Animation']   \n",
       "\n",
       "                                   production_source  \\\n",
       "0  ['Aniplex', 'Square Enix', 'Mainichi Broadcast...   \n",
       "1   ['VAP', 'Nippon Television Network', 'Shueisha']   \n",
       "2  ['Production I.G', 'Dentsu', 'Mainichi Broadca...   \n",
       "3  ['Frontier Works', 'Media Factory', 'Kadokawa ...   \n",
       "4  ['Shochiku', 'Pony Canyon', 'Kodansha', 'ABC A...   \n",
       "\n",
       "                                            synopsis  \\\n",
       "0  After a horrific alchemy experiment goes wrong...   \n",
       "1  Hunters devote themselves to accomplishing haz...   \n",
       "2  Seeking to restore humanity's diminishing hope...   \n",
       "3  Eccentric scientist Rintarou Okabe has a never...   \n",
       "4  As a wild youth, elementary school student Sho...   \n",
       "\n",
       "                      title_english              title_japanese  is_anime  \n",
       "0  Fullmetal Alchemist: Brotherhood  鋼の錬金術師 FULLMETAL ALCHEMIST         1  \n",
       "1                   Hunter x Hunter    HUNTER×HUNTER（ハンター×ハンター）         1  \n",
       "2   Attack on Titan Season 3 Part 2        進撃の巨人 Season3 Part.2         1  \n",
       "3                       Steins;Gate                 STEINS;GATE         1  \n",
       "4                    A Silent Voice                         聲の形         1  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.concat([df_anime_aligned, df_manga_aligned], ignore_index=True)\n",
    "\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>score</th>\n",
       "      <th>scored_by</th>\n",
       "      <th>status</th>\n",
       "      <th>episodes/chapters</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>source</th>\n",
       "      <th>members</th>\n",
       "      <th>favorites</th>\n",
       "      <th>sfw</th>\n",
       "      <th>approved</th>\n",
       "      <th>genres</th>\n",
       "      <th>themes</th>\n",
       "      <th>demographics</th>\n",
       "      <th>creators</th>\n",
       "      <th>production_source</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>title_english</th>\n",
       "      <th>title_japanese</th>\n",
       "      <th>is_anime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>tv</td>\n",
       "      <td>9.10</td>\n",
       "      <td>2037075</td>\n",
       "      <td>finished_airing</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2009-04-05</td>\n",
       "      <td>2010-07-04</td>\n",
       "      <td>manga</td>\n",
       "      <td>3206028</td>\n",
       "      <td>219036</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>['Action', 'Adventure', 'Drama', 'Fantasy']</td>\n",
       "      <td>['Military']</td>\n",
       "      <td>['Shounen']</td>\n",
       "      <td>['Bones']</td>\n",
       "      <td>['Aniplex', 'Square Enix', 'Mainichi Broadcast...</td>\n",
       "      <td>After a horrific alchemy experiment goes wrong...</td>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>鋼の錬金術師 FULLMETAL ALCHEMIST</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hunter x Hunter (2011)</td>\n",
       "      <td>tv</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1671587</td>\n",
       "      <td>finished_airing</td>\n",
       "      <td>148.0</td>\n",
       "      <td>2011-10-02</td>\n",
       "      <td>2014-09-24</td>\n",
       "      <td>manga</td>\n",
       "      <td>2688079</td>\n",
       "      <td>202109</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>['Action', 'Adventure', 'Fantasy']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Shounen']</td>\n",
       "      <td>['Madhouse']</td>\n",
       "      <td>['VAP', 'Nippon Television Network', 'Shueisha']</td>\n",
       "      <td>Hunters devote themselves to accomplishing haz...</td>\n",
       "      <td>Hunter x Hunter</td>\n",
       "      <td>HUNTER×HUNTER（ハンター×ハンター）</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shingeki no Kyojin Season 3 Part 2</td>\n",
       "      <td>tv</td>\n",
       "      <td>9.05</td>\n",
       "      <td>1491491</td>\n",
       "      <td>finished_airing</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2019-04-29</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>manga</td>\n",
       "      <td>2133927</td>\n",
       "      <td>55644</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>['Action', 'Drama']</td>\n",
       "      <td>['Gore', 'Military', 'Survival']</td>\n",
       "      <td>['Shounen']</td>\n",
       "      <td>['Wit Studio']</td>\n",
       "      <td>['Production I.G', 'Dentsu', 'Mainichi Broadca...</td>\n",
       "      <td>Seeking to restore humanity's diminishing hope...</td>\n",
       "      <td>Attack on Titan Season 3 Part 2</td>\n",
       "      <td>進撃の巨人 Season3 Part.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Steins;Gate</td>\n",
       "      <td>tv</td>\n",
       "      <td>9.07</td>\n",
       "      <td>1348232</td>\n",
       "      <td>finished_airing</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2011-04-06</td>\n",
       "      <td>2011-09-14</td>\n",
       "      <td>visual_novel</td>\n",
       "      <td>2463954</td>\n",
       "      <td>184312</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>['Drama', 'Sci-Fi', 'Suspense']</td>\n",
       "      <td>['Psychological', 'Time Travel']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['White Fox']</td>\n",
       "      <td>['Frontier Works', 'Media Factory', 'Kadokawa ...</td>\n",
       "      <td>Eccentric scientist Rintarou Okabe has a never...</td>\n",
       "      <td>Steins;Gate</td>\n",
       "      <td>STEINS;GATE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Koe no Katachi</td>\n",
       "      <td>movie</td>\n",
       "      <td>8.94</td>\n",
       "      <td>1540277</td>\n",
       "      <td>finished_airing</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-09-17</td>\n",
       "      <td>2016-09-17</td>\n",
       "      <td>manga</td>\n",
       "      <td>2218467</td>\n",
       "      <td>84124</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>['Award Winning', 'Drama']</td>\n",
       "      <td>['Romantic Subtext']</td>\n",
       "      <td>['Shounen']</td>\n",
       "      <td>['Kyoto Animation']</td>\n",
       "      <td>['Shochiku', 'Pony Canyon', 'Kodansha', 'ABC A...</td>\n",
       "      <td>As a wild youth, elementary school student Sho...</td>\n",
       "      <td>A Silent Voice</td>\n",
       "      <td>聲の形</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title   type  score  scored_by  \\\n",
       "0    Fullmetal Alchemist: Brotherhood     tv   9.10    2037075   \n",
       "1              Hunter x Hunter (2011)     tv   9.04    1671587   \n",
       "2  Shingeki no Kyojin Season 3 Part 2     tv   9.05    1491491   \n",
       "3                         Steins;Gate     tv   9.07    1348232   \n",
       "4                      Koe no Katachi  movie   8.94    1540277   \n",
       "\n",
       "            status  episodes/chapters  start_date    end_date        source  \\\n",
       "0  finished_airing               64.0  2009-04-05  2010-07-04         manga   \n",
       "1  finished_airing              148.0  2011-10-02  2014-09-24         manga   \n",
       "2  finished_airing               10.0  2019-04-29  2019-07-01         manga   \n",
       "3  finished_airing               24.0  2011-04-06  2011-09-14  visual_novel   \n",
       "4  finished_airing                1.0  2016-09-17  2016-09-17         manga   \n",
       "\n",
       "   members  favorites   sfw  approved  \\\n",
       "0  3206028     219036  True      True   \n",
       "1  2688079     202109  True      True   \n",
       "2  2133927      55644  True      True   \n",
       "3  2463954     184312  True      True   \n",
       "4  2218467      84124  True      True   \n",
       "\n",
       "                                        genres  \\\n",
       "0  ['Action', 'Adventure', 'Drama', 'Fantasy']   \n",
       "1           ['Action', 'Adventure', 'Fantasy']   \n",
       "2                          ['Action', 'Drama']   \n",
       "3              ['Drama', 'Sci-Fi', 'Suspense']   \n",
       "4                   ['Award Winning', 'Drama']   \n",
       "\n",
       "                             themes demographics             creators  \\\n",
       "0                      ['Military']  ['Shounen']            ['Bones']   \n",
       "1                                []  ['Shounen']         ['Madhouse']   \n",
       "2  ['Gore', 'Military', 'Survival']  ['Shounen']       ['Wit Studio']   \n",
       "3  ['Psychological', 'Time Travel']           []        ['White Fox']   \n",
       "4              ['Romantic Subtext']  ['Shounen']  ['Kyoto Animation']   \n",
       "\n",
       "                                   production_source  \\\n",
       "0  ['Aniplex', 'Square Enix', 'Mainichi Broadcast...   \n",
       "1   ['VAP', 'Nippon Television Network', 'Shueisha']   \n",
       "2  ['Production I.G', 'Dentsu', 'Mainichi Broadca...   \n",
       "3  ['Frontier Works', 'Media Factory', 'Kadokawa ...   \n",
       "4  ['Shochiku', 'Pony Canyon', 'Kodansha', 'ABC A...   \n",
       "\n",
       "                                            synopsis  \\\n",
       "0  After a horrific alchemy experiment goes wrong...   \n",
       "1  Hunters devote themselves to accomplishing haz...   \n",
       "2  Seeking to restore humanity's diminishing hope...   \n",
       "3  Eccentric scientist Rintarou Okabe has a never...   \n",
       "4  As a wild youth, elementary school student Sho...   \n",
       "\n",
       "                      title_english              title_japanese  is_anime  \n",
       "0  Fullmetal Alchemist: Brotherhood  鋼の錬金術師 FULLMETAL ALCHEMIST         1  \n",
       "1                   Hunter x Hunter    HUNTER×HUNTER（ハンター×ハンター）         1  \n",
       "2   Attack on Titan Season 3 Part 2        進撃の巨人 Season3 Part.2         1  \n",
       "3                       Steins;Gate                 STEINS;GATE         1  \n",
       "4                    A Silent Voice                         聲の形         1  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.concat([df_anime_aligned, df_manga_aligned], ignore_index=True)\n",
    "\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract year and month\n",
    "def extract_year_and_month(date):\n",
    "    try:\n",
    "        # Convert the date string to a datetime object\n",
    "        datetime_date = pd.to_datetime(date, errors='raise')\n",
    "        # Extract year and month\n",
    "        return datetime_date.year, datetime_date.month\n",
    "    except:\n",
    "        # return NaN if fails\n",
    "        return np.nan, np.nan\n",
    "    \n",
    "# Apply the function to the 'start_date' column\n",
    "df_full[['start_year', 'start_month']] = df_full['start_date'].apply(lambda x: pd.Series(extract_year_and_month(x)))\n",
    "\n",
    "# Apply the function to the 'end_date' column\n",
    "df_full[['end_year', 'end_month']] = df_full['end_date'].apply(lambda x: pd.Series(extract_year_and_month(x)))\n",
    "\n",
    "#remove useless columns\n",
    "df_full = df_full.drop(columns=['start_date', 'end_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_year</th>\n",
       "      <th>end_year</th>\n",
       "      <th>start_season</th>\n",
       "      <th>end_season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>2010</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>2014</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>2011</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Summer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_year  end_year start_season end_season\n",
       "0        2009      2010       Spring     Summer\n",
       "1        2011      2014       Autumn     Summer\n",
       "2        2019      2019       Spring     Summer\n",
       "3        2011      2011       Spring     Summer\n",
       "4        2016      2016       Summer     Summer"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to transform Start or End month into season refer to Events of Anime\n",
    "def month_to_season(month):\n",
    "    # If the data is in range, return corresponding Season of events of Anime\n",
    "    if month in [1, 2, 3]:\n",
    "        return 'Winter'\n",
    "    elif month in [4, 5, 6]:\n",
    "        return 'Spring'\n",
    "    elif month in [7, 8, 9]:\n",
    "        return 'Summer'\n",
    "    elif month in [10, 11, 12]:\n",
    "        return 'Autumn'\n",
    "    else:\n",
    "        return np.nan  # Handle unexpected cases, though this shouldn't occur with valid months\n",
    "\n",
    "# Apply the function to transform the month value to season categories\n",
    "df_full['start_season'] = df_full['start_month'].apply(month_to_season)\n",
    "df_full['end_season'] = df_full['end_month'].apply(month_to_season)\n",
    "\n",
    "# convert year to int\n",
    "df_full['start_year'] = df_full['start_year'].astype('Int64')\n",
    "df_full['end_year'] = df_full['end_year'].astype('Int64')\n",
    "\n",
    "# remove useless columns\n",
    "df_full = df_full.drop(columns=['start_month', 'end_month'])\n",
    "\n",
    "# Check for Year and Season feature\n",
    "df_full[['start_year', 'end_year', 'start_season', 'end_season']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in train set:  19453\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df_full, test_size=0.2, random_state=RANDOM_SEED)\n",
    "print('Number of rows in train set: ', len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing data in Training Set:\n",
      "\n",
      "title                    0\n",
      "type                     7\n",
      "score                 5969\n",
      "scored_by                0\n",
      "status                   0\n",
      "episodes/chapters     3887\n",
      "source               12989\n",
      "members                  0\n",
      "favorites                0\n",
      "sfw                      0\n",
      "approved                 0\n",
      "genres                   0\n",
      "themes                   0\n",
      "demographics             0\n",
      "creators                 0\n",
      "production_source        0\n",
      "synopsis                 0\n",
      "title_english            0\n",
      "title_japanese           0\n",
      "is_anime                 0\n",
      "start_year             328\n",
      "end_year              3478\n",
      "start_season           328\n",
      "end_season            3478\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check for missing data \n",
    "print(\"Number of missing data in Training Set:\\n\")\n",
    "print(train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing data in Testing Set:\n",
      "\n",
      "title                   0\n",
      "type                    1\n",
      "score                1494\n",
      "scored_by               0\n",
      "status                  0\n",
      "episodes/chapters     970\n",
      "source               3239\n",
      "members                 0\n",
      "favorites               0\n",
      "sfw                     0\n",
      "approved                0\n",
      "genres                  0\n",
      "themes                  0\n",
      "demographics            0\n",
      "creators                0\n",
      "production_source       0\n",
      "synopsis                0\n",
      "title_english           0\n",
      "title_japanese          0\n",
      "is_anime                0\n",
      "start_year             75\n",
      "end_year              875\n",
      "start_season           75\n",
      "end_season            875\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check for missing data \n",
    "print(\"Number of missing data in Testing Set:\\n\")\n",
    "print(test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MultiLabelBinarizer.fit_transform() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[96], line 31\u001b[0m\n\u001b[0;32m     25\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m ColumnTransformer([\n\u001b[0;32m     26\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msingle_category\u001b[39m\u001b[38;5;124m'\u001b[39m, single_category_pipeline, string_columns),\n\u001b[0;32m     27\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulti_category\u001b[39m\u001b[38;5;124m'\u001b[39m, multi_category_pipeline, list_columns)\n\u001b[0;32m     28\u001b[0m ], remainder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Pass through all other columns\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Fit the pipeline to the training set and transform it\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m train_processed \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Transform the test data using the same pipeline\u001b[39;00m\n\u001b[0;32m     33\u001b[0m test_processed \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mtransform(test)\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\MADS\\696\\696\\env696\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\MADS\\696\\696\\env696\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\MADS\\696\\696\\env696\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:976\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_empty_routing()\n\u001b[1;32m--> 976\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_func_on_transformers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_fit_transform_one\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_as_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result:\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fitted_transformers([])\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\MADS\\696\\696\\env696\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:885\u001b[0m, in \u001b[0;36mColumnTransformer._call_func_on_transformers\u001b[1;34m(self, X, y, func, column_as_labels, routed_params)\u001b[0m\n\u001b[0;32m    873\u001b[0m             extra_args \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    874\u001b[0m         jobs\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    875\u001b[0m             delayed(func)(\n\u001b[0;32m    876\u001b[0m                 transformer\u001b[38;5;241m=\u001b[39mclone(trans) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted \u001b[38;5;28;01melse\u001b[39;00m trans,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    882\u001b[0m             )\n\u001b[0;32m    883\u001b[0m         )\n\u001b[1;32m--> 885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    888\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\MADS\\696\\696\\env696\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\MADS\\696\\696\\env696\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\MADS\\696\\696\\env696\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\MADS\\696\\696\\env696\\Lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\MADS\\696\\696\\env696\\Lib\\site-packages\\sklearn\\pipeline.py:1310\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m   1309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1310\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit_transform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1311\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1312\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[0;32m   1313\u001b[0m             X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[0;32m   1314\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\MADS\\696\\696\\env696\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\MADS\\696\\696\\env696\\Lib\\site-packages\\sklearn\\pipeline.py:541\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    539\u001b[0m last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m    540\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(last_step, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlast_step\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit_transform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    545\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m last_step\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[0;32m    546\u001b[0m         Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    547\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\MADS\\696\\696\\env696\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: MultiLabelBinarizer.fit_transform() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import make_column_selector\n",
    "\n",
    "# Single-category columns\n",
    "string_columns = ['type', 'status', 'source', 'sfw', 'approved', 'start_season', 'end_season']\n",
    "# Multi-category columns  \n",
    "list_columns = ['genres', 'themes', 'demographics', 'creators', 'production_source']  \n",
    "\n",
    "single_category_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
    "    ('onehot', OneHotEncoder(sparse_output=False))\n",
    "])\n",
    "\n",
    "# Define the pipeline for multi-category columns\n",
    "multi_category_pipeline = Pipeline(steps=[\n",
    "    ('mlb', MultiLabelBinarizer())\n",
    "])\n",
    "\n",
    "# Combine both pipelines in a ColumnTransformer\n",
    "pipeline = ColumnTransformer([\n",
    "    ('single_category', single_category_pipeline, string_columns),\n",
    "    ('multi_category', multi_category_pipeline, list_columns)\n",
    "], remainder='passthrough')  # Pass through all other columns\n",
    "\n",
    "# Fit the pipeline to the training set and transform it\n",
    "train_processed = pipeline.fit_transform(train)\n",
    "# Transform the test data using the same pipeline\n",
    "test_processed = pipeline.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Non-numerical columns\n",
    "Non_Numerical = ['type', 'source', 'start_season', 'end_season']\n",
    "\n",
    "# Create an imputer for non-numerical data filling with 'Missing'\n",
    "categorical_imputer = SimpleImputer(strategy='constant', fill_value='Missing')\n",
    "\n",
    "# Impute non-numerical columns\n",
    "train[Non_Numerical] = categorical_imputer.fit_transform(train[Non_Numerical])\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Columns need for one-hot encoding\n",
    "# contain single category\n",
    "string_columns = ['type', 'status', 'source', 'sfw', 'approved']\n",
    "# contain multi categories\n",
    "list_columns = ['genres', 'themes', 'demographics', 'creators', 'production_source']\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False, drop='first') \n",
    "\n",
    "# Fit and transform single-category columns\n",
    "encoded_single = onehot_encoder.fit_transform(train[string_columns])\n",
    "\n",
    "# Create DataFrame for one-hot encoded columns pf string columns\n",
    "encoded_single_category_df = pd.DataFrame(encoded_single, columns = onehot_encoder.get_feature_names_out(string_columns))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Function to convert list columns into one-hot encoded columns\n",
    "def one_hot_encode_list_column(df, column_name):\n",
    "    # Create a DataFrame with each list exploded into individual rows\n",
    "    df_exploded = df[column_name].explode()\n",
    "    \n",
    "    # Create dummy variables for the exploded column (one-hot encoding)\n",
    "    dummies = pd.get_dummies(df_exploded, prefix=column_name)\n",
    "    \n",
    "    # Re-group the dummies back into the original rows by summing up the dummy columns\n",
    "    one_hot_encoded = dummies.groupby(df.index).sum()\n",
    "    \n",
    "    return one_hot_encoded\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from sklearn.impute import KNNImputer\n",
    "\n",
    "# Numerical columns\n",
    "Numerical = ['score', 'scored_by', 'episodes/chapters', 'members', 'favorites', 'start_year' , 'end_year']\n",
    "\n",
    "# Create an imputer for numerical data using KNNImputer\n",
    "knn_imputer = KNNImputer(n_neighbors=3)\n",
    "\n",
    "# Impute numerical columns\n",
    "train[Numerical] = knn_imputer.fit_transform(train[Numerical])\n",
    "\n",
    "# Check for result\n",
    "print(\"Number of missing data in Training Set:\\n\")\n",
    "print(train.isnull().sum())\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>score</th>\n",
       "      <th>scored_by</th>\n",
       "      <th>status</th>\n",
       "      <th>episodes/chapters</th>\n",
       "      <th>source</th>\n",
       "      <th>members</th>\n",
       "      <th>favorites</th>\n",
       "      <th>sfw</th>\n",
       "      <th>approved</th>\n",
       "      <th>genres</th>\n",
       "      <th>themes</th>\n",
       "      <th>demographics</th>\n",
       "      <th>creators</th>\n",
       "      <th>production_source</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>title_english</th>\n",
       "      <th>title_japanese</th>\n",
       "      <th>is_anime</th>\n",
       "      <th>start_season</th>\n",
       "      <th>end_season</th>\n",
       "      <th>elapsed_start_time</th>\n",
       "      <th>elapsed_end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7048</th>\n",
       "      <td>Toyama Kankou Anime Project</td>\n",
       "      <td>special</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>-0.198164</td>\n",
       "      <td>finished_airing</td>\n",
       "      <td>-0.394637</td>\n",
       "      <td>original</td>\n",
       "      <td>-0.228160</td>\n",
       "      <td>-0.114920</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>['Slice of Life']</td>\n",
       "      <td>['Historical']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['P.A. Works']</td>\n",
       "      <td>['The Berich']</td>\n",
       "      <td>The Toyama Kankou Anime Project is a visualiza...</td>\n",
       "      <td>Toyama Tourism Anime Project</td>\n",
       "      <td>富山観光アニメプロジェクト</td>\n",
       "      <td>1</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Spring</td>\n",
       "      <td>92.0</td>\n",
       "      <td>92.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2307</th>\n",
       "      <td>Slayers: The Motion Picture</td>\n",
       "      <td>movie</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>-0.065672</td>\n",
       "      <td>finished_airing</td>\n",
       "      <td>-0.496178</td>\n",
       "      <td>light_novel</td>\n",
       "      <td>-0.086360</td>\n",
       "      <td>-0.109830</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>['Adventure', 'Comedy', 'Fantasy']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['J.C.Staff']</td>\n",
       "      <td>['Kadokawa Shoten', 'Marubeni']</td>\n",
       "      <td>In this prequel movie to the Slayers televison...</td>\n",
       "      <td>Slayers: The Motion Picture</td>\n",
       "      <td>劇場版スレイヤーズ</td>\n",
       "      <td>1</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Summer</td>\n",
       "      <td>78.0</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9709</th>\n",
       "      <td>Arte</td>\n",
       "      <td>manga</td>\n",
       "      <td>7.910000</td>\n",
       "      <td>-0.170972</td>\n",
       "      <td>currently_publishing</td>\n",
       "      <td>0.810314</td>\n",
       "      <td>Missing</td>\n",
       "      <td>-0.159651</td>\n",
       "      <td>-0.069930</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Historical', 'Visual Arts']</td>\n",
       "      <td>['Seinen']</td>\n",
       "      <td>Kei Ookubo</td>\n",
       "      <td>['Comic Zenon']</td>\n",
       "      <td>It is early 16th-century Italy, and the city o...</td>\n",
       "      <td>Arte</td>\n",
       "      <td>アルテ</td>\n",
       "      <td>0</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Missing</td>\n",
       "      <td>96.0</td>\n",
       "      <td>101.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23892</th>\n",
       "      <td>Maou to Yuusha no Tatakai no Ura de: Game Seka...</td>\n",
       "      <td>light_novel</td>\n",
       "      <td>6.556667</td>\n",
       "      <td>-0.202049</td>\n",
       "      <td>currently_publishing</td>\n",
       "      <td>-0.083245</td>\n",
       "      <td>Missing</td>\n",
       "      <td>-0.236136</td>\n",
       "      <td>-0.115327</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>['Action', 'Fantasy']</td>\n",
       "      <td>['Isekai', 'Reincarnation', 'Video Game']</td>\n",
       "      <td>[]</td>\n",
       "      <td>Sanshouuo, Yuuki Suzuki</td>\n",
       "      <td>[]</td>\n",
       "      <td>A modern man is reincarnated into the world of...</td>\n",
       "      <td>Reincarnated into a Game as the Hero's Friend:...</td>\n",
       "      <td>魔王と勇者の戦いの裏で ～ゲーム世界に転生したけど友人の勇者が魔王討伐に旅立ったあとの国内お...</td>\n",
       "      <td>0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Missing</td>\n",
       "      <td>105.0</td>\n",
       "      <td>104.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15217</th>\n",
       "      <td>The Devil's Temptation</td>\n",
       "      <td>manhwa</td>\n",
       "      <td>6.980000</td>\n",
       "      <td>-0.199772</td>\n",
       "      <td>finished</td>\n",
       "      <td>1.737720</td>\n",
       "      <td>Missing</td>\n",
       "      <td>-0.232042</td>\n",
       "      <td>-0.114920</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>['Boys Love', 'Erotica', 'Supernatural']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Youn</td>\n",
       "      <td>['Lezhin Comics Webtoon']</td>\n",
       "      <td>Hyun was supposed to spend Christmas snuggling...</td>\n",
       "      <td>The Devil's Temptation</td>\n",
       "      <td>악마의 유혹</td>\n",
       "      <td>0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Winter</td>\n",
       "      <td>101.0</td>\n",
       "      <td>105.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title         type  \\\n",
       "7048                         Toyama Kankou Anime Project      special   \n",
       "2307                         Slayers: The Motion Picture        movie   \n",
       "9709                                                Arte        manga   \n",
       "23892  Maou to Yuusha no Tatakai no Ura de: Game Seka...  light_novel   \n",
       "15217                             The Devil's Temptation       manhwa   \n",
       "\n",
       "          score  scored_by                status  episodes/chapters  \\\n",
       "7048   5.250000  -0.198164       finished_airing          -0.394637   \n",
       "2307   7.270000  -0.065672       finished_airing          -0.496178   \n",
       "9709   7.910000  -0.170972  currently_publishing           0.810314   \n",
       "23892  6.556667  -0.202049  currently_publishing          -0.083245   \n",
       "15217  6.980000  -0.199772              finished           1.737720   \n",
       "\n",
       "            source   members  favorites    sfw  approved  \\\n",
       "7048      original -0.228160  -0.114920   True      True   \n",
       "2307   light_novel -0.086360  -0.109830   True      True   \n",
       "9709       Missing -0.159651  -0.069930   True      True   \n",
       "23892      Missing -0.236136  -0.115327   True      True   \n",
       "15217      Missing -0.232042  -0.114920  False      True   \n",
       "\n",
       "                                         genres  \\\n",
       "7048                          ['Slice of Life']   \n",
       "2307         ['Adventure', 'Comedy', 'Fantasy']   \n",
       "9709                                         []   \n",
       "23892                     ['Action', 'Fantasy']   \n",
       "15217  ['Boys Love', 'Erotica', 'Supernatural']   \n",
       "\n",
       "                                          themes demographics  \\\n",
       "7048                              ['Historical']           []   \n",
       "2307                                          []           []   \n",
       "9709               ['Historical', 'Visual Arts']   ['Seinen']   \n",
       "23892  ['Isekai', 'Reincarnation', 'Video Game']           []   \n",
       "15217                                         []           []   \n",
       "\n",
       "                      creators                production_source  \\\n",
       "7048            ['P.A. Works']                   ['The Berich']   \n",
       "2307             ['J.C.Staff']  ['Kadokawa Shoten', 'Marubeni']   \n",
       "9709                Kei Ookubo                  ['Comic Zenon']   \n",
       "23892  Sanshouuo, Yuuki Suzuki                               []   \n",
       "15217                     Youn        ['Lezhin Comics Webtoon']   \n",
       "\n",
       "                                                synopsis  \\\n",
       "7048   The Toyama Kankou Anime Project is a visualiza...   \n",
       "2307   In this prequel movie to the Slayers televison...   \n",
       "9709   It is early 16th-century Italy, and the city o...   \n",
       "23892  A modern man is reincarnated into the world of...   \n",
       "15217  Hyun was supposed to spend Christmas snuggling...   \n",
       "\n",
       "                                           title_english  \\\n",
       "7048                        Toyama Tourism Anime Project   \n",
       "2307                         Slayers: The Motion Picture   \n",
       "9709                                                Arte   \n",
       "23892  Reincarnated into a Game as the Hero's Friend:...   \n",
       "15217                             The Devil's Temptation   \n",
       "\n",
       "                                          title_japanese  is_anime  \\\n",
       "7048                                       富山観光アニメプロジェクト         1   \n",
       "2307                                           劇場版スレイヤーズ         1   \n",
       "9709                                                 アルテ         0   \n",
       "23892  魔王と勇者の戦いの裏で ～ゲーム世界に転生したけど友人の勇者が魔王討伐に旅立ったあとの国内お...         0   \n",
       "15217                                             악마의 유혹         0   \n",
       "\n",
       "      start_season end_season  elapsed_start_time   elapsed_end_time   \n",
       "7048        Spring     Spring                 92.0          92.000000  \n",
       "2307        Summer     Summer                 78.0          78.000000  \n",
       "9709        Autumn    Missing                 96.0         101.000000  \n",
       "23892       Winter    Missing                105.0         104.666667  \n",
       "15217       Spring     Winter                101.0         105.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Selecting columns to normalize\n",
    "columns_to_normalize = [\"scored_by\", \"episodes/chapters\", \"members\", \"favorites\"]\n",
    "\n",
    "earliest_start_year = train['start_year'].min()\n",
    "\n",
    "# function for Normalizing the selected columns\n",
    "def Normalizing(data):\n",
    "    data_normalized = data.copy()\n",
    "    data_normalized[columns_to_normalize] = scaler.fit_transform(train[columns_to_normalize])\n",
    "\n",
    "    # Calculate the duration by subtracting the earliest start year from all years\n",
    "    data_normalized['elapsed_start_time '] = data_normalized['start_year'] - earliest_start_year\n",
    "    data_normalized['elapsed_end_time '] = data_normalized['end_year'] - earliest_start_year\n",
    "\n",
    "    data_normalized = data_normalized.drop(columns=['start_year', 'end_year'])\n",
    "\n",
    "    return data_normalized\n",
    "\n",
    "train_normalized = Normalizing(train)\n",
    "train_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export necessary assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['assets/skipgram_model_synopsis.joblib']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# train and test df\n",
    "joblib.dump(train, 'assets/train.joblib')\n",
    "joblib.dump(test, 'assets/test.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store library version\n",
    "# run every time before you commit\n",
    "!pip freeze > requirements.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env696",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
