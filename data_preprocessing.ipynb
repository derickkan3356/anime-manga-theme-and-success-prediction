{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HK-Laptop-V639\\Documents\\GitHub\\696\\env696\\Scripts\\python.exe\n",
      "C:\\Users\\HK-Laptop-V639\\AppData\\Local\\Programs\\Python\\Python312\\python.exe\n",
      "C:\\Users\\HK-Laptop-V639\\AppData\\Local\\Microsoft\\WindowsApps\\python.exe\n"
     ]
    }
   ],
   "source": [
    "!where python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this code to make sure you install all the required libraries\n",
    "# be sure you are in virtual environment before install, otherwise it will overwrite your local environment\n",
    "\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "RANDOM_SEED = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anime = pd.read_csv(\"assets/anime.csv\")\n",
    "df_manga = pd.read_csv(\"assets/manga.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24985, 39), (64833, 30))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anime.shape, df_manga.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prepocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some short synopsis contain no information about the story of manga/title. This will introduce noise to our model. Therefore, we decide to remove those rows with extremely short synopsis.\n",
    "Example:\n",
    "- Second season of Mao Zhi Ming.\n",
    "- The second season of Shen Lan Qi Yu Wushuang Zhu.\n",
    "- Recap episode of Hakyuu Houshin Engi.\n",
    "- Fifth Season of Bungou Stray Dogs\n",
    "- 1-3. Ba_ku\\n4-5. Mephisto\n",
    "- An absurd film by Kuri Youji.\n",
    "- Included one-shot:\\nBougainvillea\n",
    "- A collection of oneshots by Nishida Higashi.\n",
    "- A movie adaptation of the TV series.\n",
    "- Short film by Kurosaka Keita.\n",
    "- Special episodes added to DVDs and Blu-rays.\n",
    "- Movie based on the 1996 TV anime with an original plot.\n",
    "- Third season of Yuan Long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned anime shape:  (8862, 21)\n",
      "cleaned manga shape:  (15447, 20)\n"
     ]
    }
   ],
   "source": [
    "def data_cleaning(input_anime, input_manga):\n",
    "    df_anime = input_anime.copy()\n",
    "    df_manga = input_manga.copy()\n",
    "\n",
    "    # remove unnecessary columns\n",
    "    df_anime = df_anime.drop(columns=['anime_id', 'total_duration', 'start_year', 'start_season', 'rating', 'main_picture', 'url', 'trailer_url', 'background', 'created_at', 'updated_at', 'episode_duration', 'broadcast_day', 'broadcast_time', 'licensors', 'title_synonyms', 'real_start_date', 'real_end_date'])\n",
    "    df_manga = df_manga.drop(columns=['manga_id', 'main_picture', 'url', 'background', 'created_at_before', 'updated_at', 'title_synonyms', 'volumes', 'real_start_date', 'real_end_date'])\n",
    "\n",
    "    # remove rows that are null in 'synopsis' and 'title', which are crucial for our project\n",
    "    df_anime.dropna(subset=['title', 'synopsis', 'title_english', 'title_japanese'], inplace=True)\n",
    "    df_manga.dropna(subset=['title', 'synopsis', 'title_english', 'title_japanese'], inplace=True)\n",
    "\n",
    "    # remove '(Sources:...)' from synopsis\n",
    "    df_anime['synopsis'] = df_anime['synopsis'].apply(lambda x: re.sub(r'\\(Source:.*\\)', '', x))\n",
    "    df_manga['synopsis'] = df_manga['synopsis'].apply(lambda x: re.sub(r'\\(Source:.*\\)', '', x))\n",
    "\n",
    "    # remove '[Written by ...]' from synopsis\n",
    "    df_anime['synopsis'] = df_anime['synopsis'].apply(lambda x: re.sub(r'\\[Written by.*\\]', '', x))\n",
    "    df_manga['synopsis'] = df_manga['synopsis'].apply(lambda x: re.sub(r'\\[Written by.*\\]', '', x))\n",
    "\n",
    "    # remove rows that have extreme short synopsis\n",
    "    df_anime = df_anime[df_anime['synopsis'].apply(lambda x: len(x) > 50)]\n",
    "    df_manga = df_manga[df_manga['synopsis'].apply(lambda x: len(x) > 50)]\n",
    "\n",
    "    print('cleaned anime shape: ', df_anime.shape)\n",
    "    print('cleaned manga shape: ', df_manga.shape)\n",
    "\n",
    "    return df_anime, df_manga\n",
    "\n",
    "df_anime_cleaned, df_manga_cleaned = data_cleaning(df_anime, df_manga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anime extra columns: \n",
      " ['episodes', 'source', 'studios', 'producers']\n"
     ]
    }
   ],
   "source": [
    "print(\"anime extra columns: \\n\", [col for col in df_anime_cleaned.columns if not col in df_manga_cleaned.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manga extra columns: \n",
      " ['chapters', 'authors', 'serializations']\n"
     ]
    }
   ],
   "source": [
    "print(\"manga extra columns: \\n\", [col for col in df_manga_cleaned.columns if not col in df_anime_cleaned.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common columns: \n",
      " ['title', 'type', 'score', 'scored_by', 'status', 'start_date', 'end_date', 'members', 'favorites', 'sfw', 'approved', 'genres', 'themes', 'demographics', 'synopsis', 'title_english', 'title_japanese']\n"
     ]
    }
   ],
   "source": [
    "print(\"common columns: \\n\", [col for col in df_anime_cleaned.columns if col in df_manga_cleaned.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def extract_author_name(author_list):\n",
    "    try:\n",
    "        author_list = ast.literal_eval(author_list)\n",
    "        \n",
    "        # Extract first and last names of authors, ignoring the others\n",
    "        author_names = [f\"{author['first_name']} {author['last_name']}\".strip() for author in author_list if author['first_name'] or author['last_name']]\n",
    "        \n",
    "        # Join names for multiple authors\n",
    "        return ', '.join(author_names) if author_names else \"Missing\"\n",
    "    \n",
    "    except (ValueError, SyntaxError, KeyError, TypeError):\n",
    "        # Handle Missing data\n",
    "        return \"Missing\"\n",
    "\n",
    "# Apply the function to the 'authors' column\n",
    "def authors_extraction(input_manga):\n",
    "    df_manga = input_manga.copy()\n",
    "    df_manga['authors'] = df_manga['authors'].apply(extract_author_name)\n",
    "\n",
    "    return df_manga\n",
    "\n",
    "df_manga_extracted = authors_extraction(df_manga_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"[{'id': 1868, 'first_name': 'Kentarou', 'last_name': 'Miura', 'role': 'Story & Art'}, {'id': 49592, 'first_name': '', 'last_name': 'Studio Gaga', 'role': 'Art'}]\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_manga_cleaned['authors'].head(1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Kentarou Miura, Studio Gaga'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_manga_extracted['authors'].head(1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra columns alignment**:\n",
    "| anime columns | manga columns | strategy |\n",
    "| --- | --- | --- |\n",
    "| episodes | chapters | episodes/chapters |\n",
    "| source | NULL | impute const 'Missing' |\n",
    "| studios | authors | creators |\n",
    "| producers | serializations | production_source |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_alignment(input_anime, input_manga):\n",
    "    df_anime = input_anime.copy()\n",
    "    df_manga = input_manga.copy()\n",
    "\n",
    "    # treat 'episodes' and 'chapters' the same, create null value for 'volume' in anime\n",
    "    df_anime.rename(columns={'episodes': 'episodes/chapters'}, inplace=True)\n",
    "    df_manga.rename(columns={'chapters': 'episodes/chapters'}, inplace=True)\n",
    "\n",
    "    # Combine studios and authors together to get creators columns\n",
    "    df_anime.rename(columns={'studios': 'creators'}, inplace=True)\n",
    "    df_manga.rename(columns={'authors': 'creators'}, inplace=True)\n",
    "\n",
    "    # Also for producers and serialization\n",
    "    df_anime.rename(columns={'producers': 'production_source'}, inplace=True)\n",
    "    df_manga.rename(columns={'serializations': 'production_source'}, inplace=True)\n",
    "\n",
    "    # To distinguish where the data from\n",
    "    df_anime['is_anime'] = 1\n",
    "    df_manga['is_anime'] = 0 \n",
    "    \n",
    "    return df_anime, df_manga\n",
    "\n",
    "df_anime_aligned, df_manga_aligned = columns_alignment(df_anime_cleaned, df_manga_extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>score</th>\n",
       "      <th>scored_by</th>\n",
       "      <th>status</th>\n",
       "      <th>episodes/chapters</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>source</th>\n",
       "      <th>members</th>\n",
       "      <th>favorites</th>\n",
       "      <th>sfw</th>\n",
       "      <th>approved</th>\n",
       "      <th>genres</th>\n",
       "      <th>themes</th>\n",
       "      <th>demographics</th>\n",
       "      <th>creators</th>\n",
       "      <th>production_source</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>title_english</th>\n",
       "      <th>title_japanese</th>\n",
       "      <th>is_anime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>tv</td>\n",
       "      <td>9.10</td>\n",
       "      <td>2037075</td>\n",
       "      <td>finished_airing</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2009-04-05</td>\n",
       "      <td>2010-07-04</td>\n",
       "      <td>manga</td>\n",
       "      <td>3206028</td>\n",
       "      <td>219036</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>['Action', 'Adventure', 'Drama', 'Fantasy']</td>\n",
       "      <td>['Military']</td>\n",
       "      <td>['Shounen']</td>\n",
       "      <td>['Bones']</td>\n",
       "      <td>['Aniplex', 'Square Enix', 'Mainichi Broadcast...</td>\n",
       "      <td>After a horrific alchemy experiment goes wrong...</td>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>鋼の錬金術師 FULLMETAL ALCHEMIST</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hunter x Hunter (2011)</td>\n",
       "      <td>tv</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1671587</td>\n",
       "      <td>finished_airing</td>\n",
       "      <td>148.0</td>\n",
       "      <td>2011-10-02</td>\n",
       "      <td>2014-09-24</td>\n",
       "      <td>manga</td>\n",
       "      <td>2688079</td>\n",
       "      <td>202109</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>['Action', 'Adventure', 'Fantasy']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Shounen']</td>\n",
       "      <td>['Madhouse']</td>\n",
       "      <td>['VAP', 'Nippon Television Network', 'Shueisha']</td>\n",
       "      <td>Hunters devote themselves to accomplishing haz...</td>\n",
       "      <td>Hunter x Hunter</td>\n",
       "      <td>HUNTER×HUNTER（ハンター×ハンター）</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shingeki no Kyojin Season 3 Part 2</td>\n",
       "      <td>tv</td>\n",
       "      <td>9.05</td>\n",
       "      <td>1491491</td>\n",
       "      <td>finished_airing</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2019-04-29</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>manga</td>\n",
       "      <td>2133927</td>\n",
       "      <td>55644</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>['Action', 'Drama']</td>\n",
       "      <td>['Gore', 'Military', 'Survival']</td>\n",
       "      <td>['Shounen']</td>\n",
       "      <td>['Wit Studio']</td>\n",
       "      <td>['Production I.G', 'Dentsu', 'Mainichi Broadca...</td>\n",
       "      <td>Seeking to restore humanity's diminishing hope...</td>\n",
       "      <td>Attack on Titan Season 3 Part 2</td>\n",
       "      <td>進撃の巨人 Season3 Part.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Steins;Gate</td>\n",
       "      <td>tv</td>\n",
       "      <td>9.07</td>\n",
       "      <td>1348232</td>\n",
       "      <td>finished_airing</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2011-04-06</td>\n",
       "      <td>2011-09-14</td>\n",
       "      <td>visual_novel</td>\n",
       "      <td>2463954</td>\n",
       "      <td>184312</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>['Drama', 'Sci-Fi', 'Suspense']</td>\n",
       "      <td>['Psychological', 'Time Travel']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['White Fox']</td>\n",
       "      <td>['Frontier Works', 'Media Factory', 'Kadokawa ...</td>\n",
       "      <td>Eccentric scientist Rintarou Okabe has a never...</td>\n",
       "      <td>Steins;Gate</td>\n",
       "      <td>STEINS;GATE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Koe no Katachi</td>\n",
       "      <td>movie</td>\n",
       "      <td>8.94</td>\n",
       "      <td>1540277</td>\n",
       "      <td>finished_airing</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-09-17</td>\n",
       "      <td>2016-09-17</td>\n",
       "      <td>manga</td>\n",
       "      <td>2218467</td>\n",
       "      <td>84124</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>['Award Winning', 'Drama']</td>\n",
       "      <td>['Romantic Subtext']</td>\n",
       "      <td>['Shounen']</td>\n",
       "      <td>['Kyoto Animation']</td>\n",
       "      <td>['Shochiku', 'Pony Canyon', 'Kodansha', 'ABC A...</td>\n",
       "      <td>As a wild youth, elementary school student Sho...</td>\n",
       "      <td>A Silent Voice</td>\n",
       "      <td>聲の形</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title   type  score  scored_by  \\\n",
       "0    Fullmetal Alchemist: Brotherhood     tv   9.10    2037075   \n",
       "1              Hunter x Hunter (2011)     tv   9.04    1671587   \n",
       "2  Shingeki no Kyojin Season 3 Part 2     tv   9.05    1491491   \n",
       "3                         Steins;Gate     tv   9.07    1348232   \n",
       "4                      Koe no Katachi  movie   8.94    1540277   \n",
       "\n",
       "            status  episodes/chapters  start_date    end_date        source  \\\n",
       "0  finished_airing               64.0  2009-04-05  2010-07-04         manga   \n",
       "1  finished_airing              148.0  2011-10-02  2014-09-24         manga   \n",
       "2  finished_airing               10.0  2019-04-29  2019-07-01         manga   \n",
       "3  finished_airing               24.0  2011-04-06  2011-09-14  visual_novel   \n",
       "4  finished_airing                1.0  2016-09-17  2016-09-17         manga   \n",
       "\n",
       "   members  favorites   sfw  approved  \\\n",
       "0  3206028     219036  True      True   \n",
       "1  2688079     202109  True      True   \n",
       "2  2133927      55644  True      True   \n",
       "3  2463954     184312  True      True   \n",
       "4  2218467      84124  True      True   \n",
       "\n",
       "                                        genres  \\\n",
       "0  ['Action', 'Adventure', 'Drama', 'Fantasy']   \n",
       "1           ['Action', 'Adventure', 'Fantasy']   \n",
       "2                          ['Action', 'Drama']   \n",
       "3              ['Drama', 'Sci-Fi', 'Suspense']   \n",
       "4                   ['Award Winning', 'Drama']   \n",
       "\n",
       "                             themes demographics             creators  \\\n",
       "0                      ['Military']  ['Shounen']            ['Bones']   \n",
       "1                                []  ['Shounen']         ['Madhouse']   \n",
       "2  ['Gore', 'Military', 'Survival']  ['Shounen']       ['Wit Studio']   \n",
       "3  ['Psychological', 'Time Travel']           []        ['White Fox']   \n",
       "4              ['Romantic Subtext']  ['Shounen']  ['Kyoto Animation']   \n",
       "\n",
       "                                   production_source  \\\n",
       "0  ['Aniplex', 'Square Enix', 'Mainichi Broadcast...   \n",
       "1   ['VAP', 'Nippon Television Network', 'Shueisha']   \n",
       "2  ['Production I.G', 'Dentsu', 'Mainichi Broadca...   \n",
       "3  ['Frontier Works', 'Media Factory', 'Kadokawa ...   \n",
       "4  ['Shochiku', 'Pony Canyon', 'Kodansha', 'ABC A...   \n",
       "\n",
       "                                            synopsis  \\\n",
       "0  After a horrific alchemy experiment goes wrong...   \n",
       "1  Hunters devote themselves to accomplishing haz...   \n",
       "2  Seeking to restore humanity's diminishing hope...   \n",
       "3  Eccentric scientist Rintarou Okabe has a never...   \n",
       "4  As a wild youth, elementary school student Sho...   \n",
       "\n",
       "                      title_english              title_japanese  is_anime  \n",
       "0  Fullmetal Alchemist: Brotherhood  鋼の錬金術師 FULLMETAL ALCHEMIST         1  \n",
       "1                   Hunter x Hunter    HUNTER×HUNTER（ハンター×ハンター）         1  \n",
       "2   Attack on Titan Season 3 Part 2        進撃の巨人 Season3 Part.2         1  \n",
       "3                       Steins;Gate                 STEINS;GATE         1  \n",
       "4                    A Silent Voice                         聲の形         1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.concat([df_anime_aligned, df_manga_aligned], ignore_index=True)\n",
    "\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract year and month\n",
    "def extract_year_and_month(date):\n",
    "    try:\n",
    "        # Convert the date string to a datetime object\n",
    "        datetime_date = pd.to_datetime(date, errors='raise')\n",
    "        # Extract year and month\n",
    "        return datetime_date.year, datetime_date.month\n",
    "    except:\n",
    "        # return NaN if fails\n",
    "        return np.nan, np.nan\n",
    "    \n",
    "# Apply the function to the 'start_date' column\n",
    "df_full[['start_year', 'start_month']] = df_full['start_date'].apply(lambda x: pd.Series(extract_year_and_month(x)))\n",
    "\n",
    "# Apply the function to the 'end_date' column\n",
    "df_full[['end_year', 'end_month']] = df_full['end_date'].apply(lambda x: pd.Series(extract_year_and_month(x)))\n",
    "\n",
    "#remove useless columns\n",
    "df_full = df_full.drop(columns=['start_date', 'end_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_year</th>\n",
       "      <th>end_year</th>\n",
       "      <th>start_season</th>\n",
       "      <th>end_season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>2010</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>2014</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>2011</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Summer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_year  end_year start_season end_season\n",
       "0        2009      2010       Spring     Summer\n",
       "1        2011      2014       Autumn     Summer\n",
       "2        2019      2019       Spring     Summer\n",
       "3        2011      2011       Spring     Summer\n",
       "4        2016      2016       Summer     Summer"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to transform Start or End month into season refer to Events of Anime\n",
    "def month_to_season(month):\n",
    "    # If the data is in range, return corresponding Season of events of Anime\n",
    "    if month in [1, 2, 3]:\n",
    "        return 'Winter'\n",
    "    elif month in [4, 5, 6]:\n",
    "        return 'Spring'\n",
    "    elif month in [7, 8, 9]:\n",
    "        return 'Summer'\n",
    "    elif month in [10, 11, 12]:\n",
    "        return 'Autumn'\n",
    "    else:\n",
    "        return np.nan  # Handle unexpected cases, though this shouldn't occur with valid months\n",
    "\n",
    "# Apply the function to transform the month value to season categories\n",
    "df_full['start_season'] = df_full['start_month'].apply(month_to_season)\n",
    "df_full['end_season'] = df_full['end_month'].apply(month_to_season)\n",
    "\n",
    "# convert year to int\n",
    "df_full['start_year'] = df_full['start_year'].astype('Int64')\n",
    "df_full['end_year'] = df_full['end_year'].astype('Int64')\n",
    "\n",
    "# remove useless columns\n",
    "df_full = df_full.drop(columns=['start_month', 'end_month'])\n",
    "\n",
    "# Check for Year and Season feature\n",
    "df_full[['start_year', 'end_year', 'start_season', 'end_season']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in train set:  19447\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df_full, test_size=0.2, random_state=RANDOM_SEED)\n",
    "print('Number of rows in train set: ', len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing data in Training Set:\n",
      "\n",
      "title                    0\n",
      "type                     6\n",
      "score                 5962\n",
      "scored_by                0\n",
      "status                   0\n",
      "episodes/chapters     3898\n",
      "source               12984\n",
      "members                  0\n",
      "favorites                0\n",
      "sfw                      0\n",
      "approved                 0\n",
      "genres                   0\n",
      "themes                   0\n",
      "demographics             0\n",
      "creators                 0\n",
      "production_source        0\n",
      "synopsis                 0\n",
      "title_english            0\n",
      "title_japanese           0\n",
      "is_anime                 0\n",
      "start_year             324\n",
      "end_year              3490\n",
      "start_season           324\n",
      "end_season            3490\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check for missing data \n",
    "print(\"Number of missing data in Training Set:\\n\")\n",
    "print(train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing data in Testing Set:\n",
      "\n",
      "title                   0\n",
      "type                    2\n",
      "score                1496\n",
      "scored_by               0\n",
      "status                  0\n",
      "episodes/chapters     959\n",
      "source               3237\n",
      "members                 0\n",
      "favorites               0\n",
      "sfw                     0\n",
      "approved                0\n",
      "genres                  0\n",
      "themes                  0\n",
      "demographics            0\n",
      "creators                0\n",
      "production_source       0\n",
      "synopsis                0\n",
      "title_english           0\n",
      "title_japanese          0\n",
      "is_anime                0\n",
      "start_year             79\n",
      "end_year              863\n",
      "start_season           79\n",
      "end_season            863\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check for missing data \n",
    "print(\"Number of missing data in Testing Set:\\n\")\n",
    "print(test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing data in Training Set:\n",
      "\n",
      "title                0\n",
      "type                 0\n",
      "score                0\n",
      "scored_by            0\n",
      "status               0\n",
      "episodes/chapters    0\n",
      "source               0\n",
      "members              0\n",
      "favorites            0\n",
      "sfw                  0\n",
      "approved             0\n",
      "genres               0\n",
      "themes               0\n",
      "demographics         0\n",
      "creators             0\n",
      "production_source    0\n",
      "synopsis             0\n",
      "title_english        0\n",
      "title_japanese       0\n",
      "is_anime             0\n",
      "start_year           0\n",
      "end_year             0\n",
      "start_season         0\n",
      "end_season           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Non-numerical columns\n",
    "Non_Numerical = ['type', 'source', 'start_season', 'end_season']\n",
    "\n",
    "# Create an imputer for non-numerical data filling with 'Missing'\n",
    "categorical_imputer = SimpleImputer(strategy='constant', fill_value='Missing')\n",
    "\n",
    "# Impute non-numerical columns\n",
    "train[Non_Numerical] = categorical_imputer.fit_transform(train[Non_Numerical])\n",
    "\n",
    "# Numerical columns\n",
    "Numerical = ['score', 'scored_by', 'episodes/chapters', 'members', 'favorites', 'start_year' , 'end_year']\n",
    "\n",
    "# Create an imputer for numerical data using KNNImputer\n",
    "knn_imputer = KNNImputer(n_neighbors=3)\n",
    "\n",
    "# Impute numerical columns\n",
    "train[Numerical] = knn_imputer.fit_transform(train[Numerical])\n",
    "\n",
    "# Check for result\n",
    "print(\"Number of missing data in Training Set:\\n\")\n",
    "print(train.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>score</th>\n",
       "      <th>scored_by</th>\n",
       "      <th>status</th>\n",
       "      <th>episodes/chapters</th>\n",
       "      <th>source</th>\n",
       "      <th>members</th>\n",
       "      <th>favorites</th>\n",
       "      <th>sfw</th>\n",
       "      <th>approved</th>\n",
       "      <th>genres</th>\n",
       "      <th>themes</th>\n",
       "      <th>demographics</th>\n",
       "      <th>creators</th>\n",
       "      <th>production_source</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>title_english</th>\n",
       "      <th>title_japanese</th>\n",
       "      <th>is_anime</th>\n",
       "      <th>start_season</th>\n",
       "      <th>end_season</th>\n",
       "      <th>elapsed_start_time</th>\n",
       "      <th>elapsed_end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7048</th>\n",
       "      <td>Toyama Kankou Anime Project</td>\n",
       "      <td>special</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>-0.198164</td>\n",
       "      <td>finished_airing</td>\n",
       "      <td>-0.394637</td>\n",
       "      <td>original</td>\n",
       "      <td>-0.228160</td>\n",
       "      <td>-0.114920</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>['Slice of Life']</td>\n",
       "      <td>['Historical']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['P.A. Works']</td>\n",
       "      <td>['The Berich']</td>\n",
       "      <td>The Toyama Kankou Anime Project is a visualiza...</td>\n",
       "      <td>Toyama Tourism Anime Project</td>\n",
       "      <td>富山観光アニメプロジェクト</td>\n",
       "      <td>1</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Spring</td>\n",
       "      <td>92.0</td>\n",
       "      <td>92.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2307</th>\n",
       "      <td>Slayers: The Motion Picture</td>\n",
       "      <td>movie</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>-0.065672</td>\n",
       "      <td>finished_airing</td>\n",
       "      <td>-0.496178</td>\n",
       "      <td>light_novel</td>\n",
       "      <td>-0.086360</td>\n",
       "      <td>-0.109830</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>['Adventure', 'Comedy', 'Fantasy']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['J.C.Staff']</td>\n",
       "      <td>['Kadokawa Shoten', 'Marubeni']</td>\n",
       "      <td>In this prequel movie to the Slayers televison...</td>\n",
       "      <td>Slayers: The Motion Picture</td>\n",
       "      <td>劇場版スレイヤーズ</td>\n",
       "      <td>1</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Summer</td>\n",
       "      <td>78.0</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9709</th>\n",
       "      <td>Arte</td>\n",
       "      <td>manga</td>\n",
       "      <td>7.910000</td>\n",
       "      <td>-0.170972</td>\n",
       "      <td>currently_publishing</td>\n",
       "      <td>0.810314</td>\n",
       "      <td>Missing</td>\n",
       "      <td>-0.159651</td>\n",
       "      <td>-0.069930</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Historical', 'Visual Arts']</td>\n",
       "      <td>['Seinen']</td>\n",
       "      <td>Kei Ookubo</td>\n",
       "      <td>['Comic Zenon']</td>\n",
       "      <td>It is early 16th-century Italy, and the city o...</td>\n",
       "      <td>Arte</td>\n",
       "      <td>アルテ</td>\n",
       "      <td>0</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Missing</td>\n",
       "      <td>96.0</td>\n",
       "      <td>101.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23892</th>\n",
       "      <td>Maou to Yuusha no Tatakai no Ura de: Game Seka...</td>\n",
       "      <td>light_novel</td>\n",
       "      <td>6.556667</td>\n",
       "      <td>-0.202049</td>\n",
       "      <td>currently_publishing</td>\n",
       "      <td>-0.083245</td>\n",
       "      <td>Missing</td>\n",
       "      <td>-0.236136</td>\n",
       "      <td>-0.115327</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>['Action', 'Fantasy']</td>\n",
       "      <td>['Isekai', 'Reincarnation', 'Video Game']</td>\n",
       "      <td>[]</td>\n",
       "      <td>Sanshouuo, Yuuki Suzuki</td>\n",
       "      <td>[]</td>\n",
       "      <td>A modern man is reincarnated into the world of...</td>\n",
       "      <td>Reincarnated into a Game as the Hero's Friend:...</td>\n",
       "      <td>魔王と勇者の戦いの裏で ～ゲーム世界に転生したけど友人の勇者が魔王討伐に旅立ったあとの国内お...</td>\n",
       "      <td>0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Missing</td>\n",
       "      <td>105.0</td>\n",
       "      <td>104.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15217</th>\n",
       "      <td>The Devil's Temptation</td>\n",
       "      <td>manhwa</td>\n",
       "      <td>6.980000</td>\n",
       "      <td>-0.199772</td>\n",
       "      <td>finished</td>\n",
       "      <td>1.737720</td>\n",
       "      <td>Missing</td>\n",
       "      <td>-0.232042</td>\n",
       "      <td>-0.114920</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>['Boys Love', 'Erotica', 'Supernatural']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Youn</td>\n",
       "      <td>['Lezhin Comics Webtoon']</td>\n",
       "      <td>Hyun was supposed to spend Christmas snuggling...</td>\n",
       "      <td>The Devil's Temptation</td>\n",
       "      <td>악마의 유혹</td>\n",
       "      <td>0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Winter</td>\n",
       "      <td>101.0</td>\n",
       "      <td>105.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title         type  \\\n",
       "7048                         Toyama Kankou Anime Project      special   \n",
       "2307                         Slayers: The Motion Picture        movie   \n",
       "9709                                                Arte        manga   \n",
       "23892  Maou to Yuusha no Tatakai no Ura de: Game Seka...  light_novel   \n",
       "15217                             The Devil's Temptation       manhwa   \n",
       "\n",
       "          score  scored_by                status  episodes/chapters  \\\n",
       "7048   5.250000  -0.198164       finished_airing          -0.394637   \n",
       "2307   7.270000  -0.065672       finished_airing          -0.496178   \n",
       "9709   7.910000  -0.170972  currently_publishing           0.810314   \n",
       "23892  6.556667  -0.202049  currently_publishing          -0.083245   \n",
       "15217  6.980000  -0.199772              finished           1.737720   \n",
       "\n",
       "            source   members  favorites    sfw  approved  \\\n",
       "7048      original -0.228160  -0.114920   True      True   \n",
       "2307   light_novel -0.086360  -0.109830   True      True   \n",
       "9709       Missing -0.159651  -0.069930   True      True   \n",
       "23892      Missing -0.236136  -0.115327   True      True   \n",
       "15217      Missing -0.232042  -0.114920  False      True   \n",
       "\n",
       "                                         genres  \\\n",
       "7048                          ['Slice of Life']   \n",
       "2307         ['Adventure', 'Comedy', 'Fantasy']   \n",
       "9709                                         []   \n",
       "23892                     ['Action', 'Fantasy']   \n",
       "15217  ['Boys Love', 'Erotica', 'Supernatural']   \n",
       "\n",
       "                                          themes demographics  \\\n",
       "7048                              ['Historical']           []   \n",
       "2307                                          []           []   \n",
       "9709               ['Historical', 'Visual Arts']   ['Seinen']   \n",
       "23892  ['Isekai', 'Reincarnation', 'Video Game']           []   \n",
       "15217                                         []           []   \n",
       "\n",
       "                      creators                production_source  \\\n",
       "7048            ['P.A. Works']                   ['The Berich']   \n",
       "2307             ['J.C.Staff']  ['Kadokawa Shoten', 'Marubeni']   \n",
       "9709                Kei Ookubo                  ['Comic Zenon']   \n",
       "23892  Sanshouuo, Yuuki Suzuki                               []   \n",
       "15217                     Youn        ['Lezhin Comics Webtoon']   \n",
       "\n",
       "                                                synopsis  \\\n",
       "7048   The Toyama Kankou Anime Project is a visualiza...   \n",
       "2307   In this prequel movie to the Slayers televison...   \n",
       "9709   It is early 16th-century Italy, and the city o...   \n",
       "23892  A modern man is reincarnated into the world of...   \n",
       "15217  Hyun was supposed to spend Christmas snuggling...   \n",
       "\n",
       "                                           title_english  \\\n",
       "7048                        Toyama Tourism Anime Project   \n",
       "2307                         Slayers: The Motion Picture   \n",
       "9709                                                Arte   \n",
       "23892  Reincarnated into a Game as the Hero's Friend:...   \n",
       "15217                             The Devil's Temptation   \n",
       "\n",
       "                                          title_japanese  is_anime  \\\n",
       "7048                                       富山観光アニメプロジェクト         1   \n",
       "2307                                           劇場版スレイヤーズ         1   \n",
       "9709                                                 アルテ         0   \n",
       "23892  魔王と勇者の戦いの裏で ～ゲーム世界に転生したけど友人の勇者が魔王討伐に旅立ったあとの国内お...         0   \n",
       "15217                                             악마의 유혹         0   \n",
       "\n",
       "      start_season end_season  elapsed_start_time   elapsed_end_time   \n",
       "7048        Spring     Spring                 92.0          92.000000  \n",
       "2307        Summer     Summer                 78.0          78.000000  \n",
       "9709        Autumn    Missing                 96.0         101.000000  \n",
       "23892       Winter    Missing                105.0         104.666667  \n",
       "15217       Spring     Winter                101.0         105.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Selecting columns to normalize\n",
    "columns_to_normalize = [\"scored_by\", \"episodes/chapters\", \"members\", \"favorites\"]\n",
    "\n",
    "earliest_start_year = train['start_year'].min()\n",
    "\n",
    "# function for Normalizing the selected columns\n",
    "def Normalizing(data):\n",
    "    data_normalized = data.copy()\n",
    "    data_normalized[columns_to_normalize] = scaler.fit_transform(train[columns_to_normalize])\n",
    "\n",
    "    # Calculate the duration by subtracting the earliest start year from all years\n",
    "    data_normalized['elapsed_start_time '] = data_normalized['start_year'] - earliest_start_year\n",
    "    data_normalized['elapsed_end_time '] = data_normalized['end_year'] - earliest_start_year\n",
    "\n",
    "    data_normalized = data_normalized.drop(columns=['start_year', 'end_year'])\n",
    "\n",
    "    return data_normalized\n",
    "\n",
    "train_normalized = Normalizing(train)\n",
    "train_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization and lemmatization by keeping `{'NOUN', 'VERB', 'ADJ', 'PROPN', 'ADV'}` and replace named entity with place holder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after filtering empty token:  19301\n"
     ]
    }
   ],
   "source": [
    "# tokenization and lemmatization\n",
    "import spacy\n",
    "\n",
    "POS_TO_KEEP = {'NOUN', 'VERB', 'ADJ', 'PROPN', 'ADV'}\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "stop_words = nlp.Defaults.stop_words\n",
    "\n",
    "def tokenization(doc):\n",
    "    \"\"\"\n",
    "    Filter out number.\n",
    "    Replace person, organization, and location entities with '<ent_type_>'\n",
    "    Return lemma if its POS is in `POS_TO_KEEP` and not in stop_words.\n",
    "    \"\"\"\n",
    "    tokens = []\n",
    "\n",
    "    for token in doc:\n",
    "        if token.is_digit:\n",
    "            # filter out numeric tokens\n",
    "            continue\n",
    "\n",
    "        if token.ent_type_ in ['PERSON', 'ORG', 'GPE']:\n",
    "            # replace person, organization, and location entities\n",
    "            tokens.append(f'<{token.ent_type_}>')\n",
    "            \n",
    "        elif token.pos_ in POS_TO_KEEP and not token.lemma_ in stop_words:\n",
    "            # return lemma if its POS is in `POS_TO_KEEP` and not in stop_words\n",
    "            tokens.append(token.lemma_)\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# use nlp.pipe for batch processing\n",
    "train['title_en_token'] = [\n",
    "    tokenization(doc) for doc in nlp.pipe(train['title_english'], batch_size=100, n_process=-1)\n",
    "]\n",
    "train['synopsis_token'] = [\n",
    "    tokenization(doc) for doc in nlp.pipe(train['synopsis'], batch_size=100, n_process=-1)\n",
    "]\n",
    "\n",
    "# filter out empty token\n",
    "train = train[train['title_en_token'].apply(lambda x: len(x) > 0) & train['synopsis_token'].apply(lambda x: len(x) > 0)] # both columns cannot be empty\n",
    "\n",
    "print('Number of rows after filtering empty token: ', len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_english</th>\n",
       "      <th>title_en_token</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>synopsis_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9075</th>\n",
       "      <td>Teasing Master Takagi-san</td>\n",
       "      <td>[Teasing, Master, Takagi, san]</td>\n",
       "      <td>With a smirk, the mischievous middle school boy Nishikata glances over at Takagi, the girl seated next to him in class. He has just devised a master plan to finally get back at her for all the merciless teasing inflicted upon him. As he is about to set his plan into motion, Takagi intervenes with a single comment that halts Nishikata right in his tracks. She had turned the tables on him yet again.\\n \\n\"If you blush, you lose.\" That has been the unwritten rule set between the two ever since they encountered one another in middle school. Day after day, loss after loss, Nishikata strives to see Takagi red with embarrassment, but his futile attempts are only met by further ridicule. Beyond this vicious cycle of trying to outwit one another, will their relationship ever evolve?\\n\\n</td>\n",
       "      <td>[smirk, mischievous, middle, school, boy, &lt;ORG&gt;, glance, &lt;ORG&gt;, girl, seat, class, devise, master, plan, finally, merciless, teasing, inflict, set, plan, motion, &lt;ORG&gt;, intervene, single, comment, halt, &lt;ORG&gt;, right, track, turn, table, blush, lose, unwritten, rule, set, encounter, middle, school, day, day, loss, loss, &lt;ORG&gt;, strive, &lt;ORG&gt;, red, embarrassment, futile, attempt, meet, ridicule, vicious, cycle, try, outwit, relationship, evolve]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title_english                  title_en_token  \\\n",
       "9075  Teasing Master Takagi-san  [Teasing, Master, Takagi, san]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 synopsis  \\\n",
       "9075  With a smirk, the mischievous middle school boy Nishikata glances over at Takagi, the girl seated next to him in class. He has just devised a master plan to finally get back at her for all the merciless teasing inflicted upon him. As he is about to set his plan into motion, Takagi intervenes with a single comment that halts Nishikata right in his tracks. She had turned the tables on him yet again.\\n \\n\"If you blush, you lose.\" That has been the unwritten rule set between the two ever since they encountered one another in middle school. Day after day, loss after loss, Nishikata strives to see Takagi red with embarrassment, but his futile attempts are only met by further ridicule. Beyond this vicious cycle of trying to outwit one another, will their relationship ever evolve?\\n\\n   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                      synopsis_token  \n",
       "9075  [smirk, mischievous, middle, school, boy, <ORG>, glance, <ORG>, girl, seat, class, devise, master, plan, finally, merciless, teasing, inflict, set, plan, motion, <ORG>, intervene, single, comment, halt, <ORG>, right, track, turn, table, blush, lose, unwritten, rule, set, encounter, middle, school, day, day, loss, loss, <ORG>, strive, <ORG>, red, embarrassment, futile, attempt, meet, ridicule, vicious, cycle, try, outwit, relationship, evolve]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# review tokenization\n",
    "with pd.option_context('display.max_colwidth', None):\n",
    "    display(train[['title_english', 'title_en_token', 'synopsis', 'synopsis_token']].sample(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since titles and synopses play different roles (titles are short and often genre-indicative, while synopses provide detailed content descriptions), we use two separate vectorizers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Titles are shorter and often contain rare, context-rich words that are crucial for capturing unique meaning, while synopses are longer and contain more common words, making them less reliant on capturing rare vocabulary. So, we use a higher `max_features` or `vector_size` for title to ensures it capture these niche terms and their relationships, while use lower for synopsis to focus on the more frequently relevant words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# initialize title tfidf\n",
    "tfidf_title = TfidfVectorizer(\n",
    "    ngram_range=(1,1),  # uni-gram\n",
    "    min_df=1,           # don't filter rare words as they are important for title\n",
    "    max_df=0.8,         # filter out very common words\n",
    ")\n",
    "\n",
    "# initialize synopsis tfidf\n",
    "tfidf_synopsis = TfidfVectorizer(\n",
    "    ngram_range=(1,2),  # uni-gram or bi-gram\n",
    "    max_features=2000,  # focus on the more frequently relevant words\n",
    "    min_df=2,           # filter out extremely rare words\n",
    "    max_df=0.8,         # filter out very common words\n",
    ")\n",
    "\n",
    "# train tfidf\n",
    "title_en_tfidf_matrix = tfidf_title.fit_transform(train['title_en_token'].apply(lambda x: \" \".join(x)))\n",
    "synopsis_tfidf_matrix = tfidf_synopsis.fit_transform(train['synopsis_token'].apply(lambda x: \" \".join(x)))\n",
    "\n",
    "# add result to train df\n",
    "train['title_en_tfidf'] = [title_en_tfidf_matrix[i] for i in range(title_en_tfidf_matrix.shape[0])]\n",
    "train['synopsis_tfidf'] = [synopsis_tfidf_matrix[i] for i in range(synopsis_tfidf_matrix.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For word embedding, we choose **Word2Vec - Skip-gram** because it tends to capture rare words more effectively (e.g. niche anime/manga-specific vocabulary), comparing to Word2Vec - CBOW and GloVe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word embedding\n",
    "import multiprocessing\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# dynamically determine the number of CPU cores\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "\n",
    "# train title skipgram model\n",
    "skipgram_model_title = Word2Vec(\n",
    "    train['title_en_token'].tolist(),\n",
    "    sg=1,               # skip-gram\n",
    "    vector_size=300,    # title use higher dim\n",
    "    window=2,           # title use smaller window size\n",
    "    min_count=1,        # titles may contain rare but important words\n",
    "    epochs=30,          # title are shorter, need more epochs to train\n",
    "    workers=num_workers,\n",
    "    seed=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# train synopsis skipgram model\n",
    "skipgram_model_synopsis = Word2Vec(\n",
    "    train['synopsis_token'].tolist(),\n",
    "    sg=1,               # skip-gram\n",
    "    vector_size=150,    # synopsis use lower dim\n",
    "    window=5,           # synopsis use larger window size\n",
    "    min_count=2,        # filter out extremely rare words\n",
    "    epochs=15,\n",
    "    workers=num_workers,\n",
    "    seed=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# clean tokens that does not exist in the skipgram vocab (because of `min_count`)\n",
    "model_vocab = set(skipgram_model_synopsis.wv.index_to_key)\n",
    "train['synopsis_token'] = train['synopsis_token'].apply(lambda x: [token for token in x if token in model_vocab])\n",
    "train = train[train['synopsis_token'].apply(lambda x: len(x) > 0)]  # filter out empty entry after clean tokens\n",
    "\n",
    "# apply skipgram model\n",
    "train['title_en_skipgram'] = train['title_en_token'].apply(lambda x: skipgram_model_title.wv[x])\n",
    "train['synopsis_skipgram'] = train['synopsis_token'].apply(lambda x: skipgram_model_synopsis.wv[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_japanese</th>\n",
       "      <th>title_english</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>title_en_tfidf</th>\n",
       "      <th>title_en_skipgram</th>\n",
       "      <th>synopsis_tfidf</th>\n",
       "      <th>synopsis_skipgram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22683</th>\n",
       "      <td>アザトメイキング＋</td>\n",
       "      <td>Azato Making+</td>\n",
       "      <td>1. Shuujuu Emotion\\n2. Shuujuu Dreaming\\n3. Sh...</td>\n",
       "      <td>(0, 5387)\\t1.0</td>\n",
       "      <td>[[-0.5122074, -0.1496037, 0.0459687, -0.406966...</td>\n",
       "      <td>(0, 1149)\\t0.25654260098412046\\n  (0, 1216)\\...</td>\n",
       "      <td>[[0.07682086, -0.14349373, 0.04345498, 0.18370...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10318</th>\n",
       "      <td>キミに恋していーですか。</td>\n",
       "      <td>May I be in love with you?</td>\n",
       "      <td>Chigira Ruiji is a man born with the face of a...</td>\n",
       "      <td>(0, 4365)\\t1.0</td>\n",
       "      <td>[[-0.009436031, -0.3950392, 0.030088374, -0.30...</td>\n",
       "      <td>(0, 1149)\\t0.1875630314123266\\n  (0, 782)\\t0...</td>\n",
       "      <td>[[0.07682086, -0.14349373, 0.04345498, 0.18370...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22950</th>\n",
       "      <td>소년들은 무엇을 하고 있을까</td>\n",
       "      <td>10th Dimension Boys</td>\n",
       "      <td>In another dimension, anything can happen in y...</td>\n",
       "      <td>(0, 925)\\t0.41877466769782945\\n  (0, 1974)\\t...</td>\n",
       "      <td>[[-0.086346425, -0.07495511, 0.10810716, -0.07...</td>\n",
       "      <td>(0, 707)\\t0.19858748620401637\\n  (0, 936)\\t0...</td>\n",
       "      <td>[[0.07777373, -0.31890902, -0.44942433, 0.4214...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15893</th>\n",
       "      <td>ピュア・トランス</td>\n",
       "      <td>Pure Trance</td>\n",
       "      <td>In this dreamy science fiction fantasy, Junko ...</td>\n",
       "      <td>(0, 5631)\\t1.0</td>\n",
       "      <td>[[-0.06057793, -0.35592693, 0.06409358, -0.183...</td>\n",
       "      <td>(0, 1149)\\t0.09993168318485023\\n  (0, 1216)\\...</td>\n",
       "      <td>[[0.20115462, -0.011873402, -0.45442194, -0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8428</th>\n",
       "      <td>巨人の星対鉄腕アトム</td>\n",
       "      <td>Star of the Giants vs Astro Boy</td>\n",
       "      <td>Star of the Giants vs Astro Boy is an anime cr...</td>\n",
       "      <td>(0, 5387)\\t0.3197068523302739\\n  (0, 5631)\\t...</td>\n",
       "      <td>[[-0.045020744, -0.073905714, 0.17955288, 0.01...</td>\n",
       "      <td>(0, 1149)\\t0.4376688511097766\\n  (0, 1216)\\t...</td>\n",
       "      <td>[[-0.064565, -0.39407685, -0.3785122, 0.230841...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        title_japanese                    title_english  \\\n",
       "22683        アザトメイキング＋                    Azato Making+   \n",
       "10318     キミに恋していーですか。       May I be in love with you?   \n",
       "22950  소년들은 무엇을 하고 있을까              10th Dimension Boys   \n",
       "15893         ピュア・トランス                      Pure Trance   \n",
       "8428        巨人の星対鉄腕アトム  Star of the Giants vs Astro Boy   \n",
       "\n",
       "                                                synopsis  \\\n",
       "22683  1. Shuujuu Emotion\\n2. Shuujuu Dreaming\\n3. Sh...   \n",
       "10318  Chigira Ruiji is a man born with the face of a...   \n",
       "22950  In another dimension, anything can happen in y...   \n",
       "15893  In this dreamy science fiction fantasy, Junko ...   \n",
       "8428   Star of the Giants vs Astro Boy is an anime cr...   \n",
       "\n",
       "                                          title_en_tfidf  \\\n",
       "22683                                     (0, 5387)\\t1.0   \n",
       "10318                                     (0, 4365)\\t1.0   \n",
       "22950    (0, 925)\\t0.41877466769782945\\n  (0, 1974)\\t...   \n",
       "15893                                     (0, 5631)\\t1.0   \n",
       "8428     (0, 5387)\\t0.3197068523302739\\n  (0, 5631)\\t...   \n",
       "\n",
       "                                       title_en_skipgram  \\\n",
       "22683  [[-0.5122074, -0.1496037, 0.0459687, -0.406966...   \n",
       "10318  [[-0.009436031, -0.3950392, 0.030088374, -0.30...   \n",
       "22950  [[-0.086346425, -0.07495511, 0.10810716, -0.07...   \n",
       "15893  [[-0.06057793, -0.35592693, 0.06409358, -0.183...   \n",
       "8428   [[-0.045020744, -0.073905714, 0.17955288, 0.01...   \n",
       "\n",
       "                                          synopsis_tfidf  \\\n",
       "22683    (0, 1149)\\t0.25654260098412046\\n  (0, 1216)\\...   \n",
       "10318    (0, 1149)\\t0.1875630314123266\\n  (0, 782)\\t0...   \n",
       "22950    (0, 707)\\t0.19858748620401637\\n  (0, 936)\\t0...   \n",
       "15893    (0, 1149)\\t0.09993168318485023\\n  (0, 1216)\\...   \n",
       "8428     (0, 1149)\\t0.4376688511097766\\n  (0, 1216)\\t...   \n",
       "\n",
       "                                       synopsis_skipgram  \n",
       "22683  [[0.07682086, -0.14349373, 0.04345498, 0.18370...  \n",
       "10318  [[0.07682086, -0.14349373, 0.04345498, 0.18370...  \n",
       "22950  [[0.07777373, -0.31890902, -0.44942433, 0.4214...  \n",
       "15893  [[0.20115462, -0.011873402, -0.45442194, -0.03...  \n",
       "8428   [[-0.064565, -0.39407685, -0.3785122, 0.230841...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['title_japanese', 'title_english', 'synopsis', 'title_en_tfidf', 'title_en_skipgram', 'synopsis_tfidf', 'synopsis_skipgram']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export necessary assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['assets/skipgram_model_synopsis.joblib']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# train and test df\n",
    "joblib.dump(train, 'assets/train.joblib')\n",
    "joblib.dump(test, 'assets/test.joblib')\n",
    "\n",
    "# tfidf_matrix\n",
    "joblib.dump(title_en_tfidf_matrix, 'assets/title_en_tfidf_matrix.joblib')\n",
    "joblib.dump(synopsis_tfidf_matrix, 'assets/synopsis_tfidf_matrix.joblib')\n",
    "\n",
    "# tfidf vectorizer\n",
    "joblib.dump(tfidf_title, 'assets/tfidf_title_vectorizer.joblib')\n",
    "joblib.dump(tfidf_synopsis, 'assets/tfidf_synopsis_vectorizer.joblib')\n",
    "\n",
    "# skipgram\n",
    "joblib.dump(skipgram_model_title, 'assets/skipgram_model_title.joblib')\n",
    "joblib.dump(skipgram_model_synopsis, 'assets/skipgram_model_synopsis.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store library version\n",
    "# run every time before you commit\n",
    "!pip freeze > requirements.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env696",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
